# Survey of Business Owners (SBO) {-}

<a href="https://github.com/asdfree/sbo/actions"><img src="https://github.com/asdfree/sbo/actions/workflows/r.yml/badge.svg" alt="Github Actions Badge"></a>

Before its replacement in 2018 by the [Annual Business Survey](https://www.census.gov/newsroom/press-releases/2018/annual-business-survey.html), nearly every tax-filing sole proprietorship, partnership, and corporation nationwide answered its [questionnaire](https://www.census.gov/programs-surveys/sbo/technical-documentation/questionnaires.html). 2007 remains sole year of microdata.

* One table with one row per firm per state per industry.

* A complex sample survey designed to generalize to [most firms in the United States](https://www.census.gov/programs-surveys/sbo/technical-documentation/methodology.2007.html), public microdata includes [classifiable (non-identifiable) firms](https://www2.census.gov/econ/sbo/07/pums/2007_sbo_pums_users_guide.pdf#page=17), i.e. nearly all businesses but only about half of workers.

* Released quinquennially from 1972 until 2012 in the Economic Census with no updates expected.

* Administered by the [U.S. Census Bureau](http://www.census.gov/). [Annual Business Survey](https://www.census.gov/programs-surveys/abs/) now conducted jointly with the [National Center for Science and Engineering Statistics](https://ncses.nsf.gov/) within the [National Science Foundation](https://www.nsf.gov/).

---

Please skim before you begin:

1. [2007 Survey of Business Owners (SBO) Public Use Microdata Sample (PUMS) Data Users Guide](https://www2.census.gov/econ/sbo/07/pums/2007_sbo_pums_users_guide.pdf)

2. [Survey of Business Owners (SBO) - Survey Results: 2012](https://www.census.gov/library/publications/2012/econ/2012-sbo.html)

3. This human-composed haiku or a bouquet of [artificial intelligence-generated limericks](https://www.gnod.com/search/ai#q=write%20a%20limerick-style%20poem%20about%20the%20Survey of Business Owners)

```{r}
# butchers, chandlers, baked
# sea shanty, filial pie
# call your mom and pop
```

---

## Function Definitions {-}
Define functions specific to only this dataset:

```{r eval = FALSE , results = "hide" }
#' dual design calculations for the survey of business owners
#'
#' the code{mitools::sbo_MIcombine} variant includes a 2007-specific variance adjustment. this will change in other years.
#' this adjustment statistic was pulled from the middle of page 8
#' url{https://www2.census.gov/econ/sbo/07/pums/2007_sbo_pums_users_guide.pdf#page=8}
#'
#' each of these sbo-specific functions contain a variant of some other code{library(survey)} function that also maintains the census bureau's dual design calculation.
#' these functions expect both the coefficient and the variance survey objects
#'
sbo_MIcombine <-
	function( x , adjustment = 1.992065 ){
	
		# just pull the structure of a variance-covariance matrix
		variance.shell <- suppressWarnings( vcov( x$var[[1]] ) )
		
		# initiate a function that will overwrite the diagonals.
		diag.replacement <-	
			function( z ){
				diag( variance.shell ) <- coef( z )
				variance.shell
			}
			
		# overwrite all the diagonals in the variance svy.sbo object
		coef.variances <- lapply( x$var , diag.replacement )
	
		# add 'em all together and divide by ten.
		midpoint <- Reduce( '+' , coef.variances ) / 10
	
		# initiate another function that takes some object,
		# subtracts the midpoint, squares it, and divides by ninety
		midpoint.var <- function( z ){ 1/10 * ( ( midpoint - z )^2 / 9 ) }
	
		# sum up all the differences into a single object
		variance <- Reduce( '+' , lapply( coef.variances , midpoint.var ) )
		
		# adjust every. single. number.
		adj_var <- adjustment * variance

		# construct a result that looks a lot like
		# other sbo_MIcombine methods.
		rval <-
			list( 
				coefficients = coef( x$coef ) ,
				variance = adj_var
			)
		
		# call it an MIresult class, just like all other sbo_MIcombine results.
		class( rval ) <- 'MIresult'
		
		# return it at the end of the function.
		rval
	}

sbo_with <-
	function ( sbo.svy , expr , ... ){
	
		pf <- parent.frame()
		
		expr <- substitute( expr )
		
		expr$design <- as.name(".design")

		# this pulls in means, medians, totals, etc.
		# notice it uses sbo.svy$coef
		results <- eval( expr , list( .design = sbo.svy$coef ) )
		
		gc()
		
		# this is used to calculate the variance, adjusted variance, standard error
		# notice it uses the sbo.svy$var object
		variances <- 
			lapply( 
				sbo.svy$var$designs , 
				function( .design ){ 
					eval( expr , list( .design = .design ) , enclos = pf ) 
				} 
			)
		
		gc()
		
		# combine both results..
		rval <- list( coef = results , var = variances )
		
		# ..into a brand new object class
		class( rval ) <- 'imputationResultList'
		
		gc()
		
		# and return it.
		rval
	}

sbo_subset <-
	function( x , ... ){
		
		# subset the survey object that's going to be used for
		# means, medians, totals, etc.
		coef.sub <- subset( x$coef , ... )
		
		gc()
		
		# replicate `var.sub` so it's got all the same attributes as `x$var`
		var.sub <- x$var
		
		# but then overwrite the `designs` attribute with a subset
		var.sub$designs <- lapply( x$var$designs , subset , ... )
		
		gc()
		
		# now re-create the `sbosvyimputationList` just as before
		sub.svy <-
			list(
				coef = coef.sub ,
				var = var.sub
			)
		
		# ..class it..
		sub.svy$call <- sys.call(-1)
		
		gc()
		
		# ..return it. done.
		sub.svy
	}

sbo_update <-
	function( x , ... ){
		
		# update the survey object that's going to be used for
		# means, medians, totals, etc.
		coef.upd <- update( x$coef , ... )
		
		gc()
		
		# replicate `var.upd` so it's got all the same attributes as `x$var`
		var.upd <- x$var
		
		# but then overwrite the `designs` attribute with an update
		var.upd$designs <- lapply( x$var$designs , update , ... )
		
		gc()
		
		# now re-create the `sbosvyimputationList` just as before
		upd.svy <-
			list(
				coef = coef.upd ,
				var = var.upd
			)
			
		gc()
		
		# ..return it. done.
		upd.svy
	}

sbo_degf <- function( x ) degf( x$coef )

```
---

## Download, Import, Preparation {-}

```{r eval = FALSE , results = "hide" }
library(httr)
library(readr)

tf <- tempfile()

this_url <- "https://www2.census.gov/programs-surveys/sbo/datasets/2007/pums_csv.zip"

GET( this_url , write_disk( tf ) )

sbo_tbl <- read_csv( tf )

sbo_df <- data.frame( sbo_tbl )

names( sbo_df ) <- tolower( names( sbo_df ) )

sbo_df[ , 'one' ] <- 1

# and use the weights displayed in the census bureau's technical documentation
sbo_df[ , 'newwgt' ] <- 10 * sbo_df[ , 'tabwgt' ] * sqrt( 1 - 1 / sbo_df[ , 'tabwgt' ] )
# https://www2.census.gov/econ/sbo/07/pums/2007_sbo_pums_users_guide.pdf#page=7

# replace percent missings with zeroes
for( i in 1:4 ) sbo_df[ is.na( sbo_df[ , paste0( 'pct' , i ) ] ) , paste0( 'pct' , i ) ] <- 0

# count ownership ethnicity
sbo_df[ , 'hispanic_pct' ] <- sbo_df[ , 'nonhispanic_pct' ] <- 0

# count ownership gender
sbo_df[ , 'male_pct' ] <- sbo_df[ , 'female_pct' ] <- 0

for( i in 1:4 ) {

	sbo_df[ sbo_df[ , paste0( 'eth' , i ) ] %in% 'H' , 'hispanic_pct' ] <-
		sbo_df[ sbo_df[ , paste0( 'eth' , i ) ] %in% 'H' , 'hispanic_pct' ] +
		sbo_df[ sbo_df[ , paste0( 'eth' , i ) ] %in% 'H' , paste0( 'pct' , i ) ]
		
	sbo_df[ sbo_df[ , paste0( 'eth' , i ) ] %in% 'N' , 'nonhispanic_pct' ] <-
		sbo_df[ sbo_df[ , paste0( 'eth' , i ) ] %in% 'N' , 'nonhispanic_pct' ] +
		sbo_df[ sbo_df[ , paste0( 'eth' , i ) ] %in% 'N' , paste0( 'pct' , i ) ]
		
	sbo_df[ sbo_df[ , paste0( 'sex' , i ) ] %in% 'M' , 'male_pct' ] <-
		sbo_df[ sbo_df[ , paste0( 'sex' , i ) ] %in% 'M' , 'male_pct' ] +
		sbo_df[ sbo_df[ , paste0( 'sex' , i ) ] %in% 'M' , paste0( 'pct' , i ) ]
		
	sbo_df[ sbo_df[ , paste0( 'sex' , i ) ] %in% 'F' , 'female_pct' ] <-
		sbo_df[ sbo_df[ , paste0( 'sex' , i ) ] %in% 'F' , 'female_pct' ] +
		sbo_df[ sbo_df[ , paste0( 'sex' , i ) ] %in% 'F' , paste0( 'pct' , i ) ]
		
}
```

### Save locally \ {-}

Save the object at any point:

```{r eval = FALSE , results = "hide" }
# sbo_fn <- file.path( path.expand( "~" ) , "SBO" , "this_file.rds" )
# saveRDS( sbo_df , file = sbo_fn , compress = FALSE )
```

Load the same object:

```{r eval = FALSE , results = "hide" }
# sbo_df <- readRDS( sbo_fn )
```

### Survey Design Definition {-}
Construct a multiply-imputed, complex sample survey design:

```{r messages = FALSE , eval = FALSE }
library(survey)
library(mitools)

var_list <- NULL

for( i in 1:10 ) { var_list <- c( var_list , list( subset( sbo_df , rg == i ) ) ) }

#####################################################
# survey design for a hybrid database-backed object #
#####################################################

# create a survey design object with the SBO design
# to use for the coefficients: means, medians, totals, etc.
sbo_coef <-
	svydesign(
		id = ~ 1 ,
		weight = ~ tabwgt ,
		data = sbo_df
	)
# this one just uses the original table `x`

# create a survey design object with the SBO design
# to use for the variance and standard error
sbo_var <-
	svydesign(
		id = ~ 1 ,
		weight = ~ newwgt ,
		data = imputationList( var_list )
	)

# rm( var_list ) ; gc()
# this one uses the ten `x1` thru `x10` tables you just made.

# slap 'em together into a single list object..
sbo_design <- list( coef = sbo_coef , var = sbo_var )
class( sbo_design ) <- 'sbosvyimputationList'

```

### Variable Recoding {-}

Add new columns to the data set:
```{r eval = FALSE , results = "hide" }
sbo_design <- 
	sbo_update( 
		sbo_design , 
		established_before_2000 =
			ifelse( established %in% c( '0' , 'A' ) , NA , as.numeric( established < 4 ) ) ,
			
		healthins =
			factor( healthins , levels = 1:2 ,
				labels = c( "offered health insurance" , "did not offer health insurance" )
			) ,
			
		hispanic_ownership =
			factor(
				ifelse( hispanic_pct == nonhispanic_pct , 2 ,
				ifelse( hispanic_pct > nonhispanic_pct , 1 , 
				ifelse( nonhispanic_pct > hispanic_pct , 3 , NA ) ) ) ,
				levels = 1:3 ,
				labels = c( 'hispanic' , 'equally hispanic/non-hispanic' , 'non-hispanic' )
			) ,
			
		gender_ownership =
			factor(
				ifelse( male_pct == female_pct , 2 ,
				ifelse( male_pct > female_pct , 1 , 
				ifelse( female_pct > male_pct , 3 , NA ) ) ) ,
				levels = 1:3 ,
				labels = c( 'male' , 'equally male/female' , 'female' )
			)
		
	)
```

---

## Analysis Examples with the `survey` library \ {-}

### Unweighted Counts {-}

Count the unweighted number of records in the survey sample, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svyby( ~ one , ~ one , unwtd.count ) ) )

sbo_MIcombine( sbo_with( sbo_design , svyby( ~ one , ~ gender_ownership , unwtd.count ) ) )
```

### Weighted Counts {-}
Count the weighted size of the generalizable population, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svytotal( ~ one ) ) )

sbo_MIcombine( sbo_with( sbo_design ,
	svyby( ~ one , ~ gender_ownership , svytotal )
) )
```

### Descriptive Statistics {-}

Calculate the mean (average) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svymean( ~ receipts_noisy ) ) )

sbo_MIcombine( sbo_with( sbo_design ,
	svyby( ~ receipts_noisy , ~ gender_ownership , svymean )
) )
```

Calculate the distribution of a categorical variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svymean( ~ n07_employer , na.rm = TRUE ) ) )

sbo_MIcombine( sbo_with( sbo_design ,
	svyby( ~ n07_employer , ~ gender_ownership , svymean , na.rm = TRUE )
) )
```

Calculate the sum of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svytotal( ~ receipts_noisy ) ) )

sbo_MIcombine( sbo_with( sbo_design ,
	svyby( ~ receipts_noisy , ~ gender_ownership , svytotal )
) )
```

Calculate the weighted sum of a categorical variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svytotal( ~ n07_employer , na.rm = TRUE ) ) )

sbo_MIcombine( sbo_with( sbo_design ,
	svyby( ~ n07_employer , ~ gender_ownership , svytotal , na.rm = TRUE )
) )
```

Calculate the median (50th percentile) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design ,
	svyquantile(
		~ receipts_noisy ,
		0.5 , se = TRUE 
) ) )

sbo_MIcombine( sbo_with( sbo_design ,
	svyby(
		~ receipts_noisy , ~ gender_ownership , svyquantile ,
		0.5 , se = TRUE ,
		ci = TRUE 
) ) )
```

Estimate a ratio:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design ,
	svyratio( numerator = ~ receipts_noisy , denominator = ~ employment_noisy )
) )
```

### Subsetting {-}

Restrict the survey design to jointly owned by husband and wife:
```{r eval = FALSE , results = "hide" }
sub_sbo_design <- sbo_subset( sbo_design , husbwife %in% 1:3 )
```
Calculate the mean (average) of this subset:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sub_sbo_design , svymean( ~ receipts_noisy ) ) )
```

### Measures of Uncertainty {-}

Extract the coefficient, standard error, confidence interval, and coefficient of variation from any descriptive statistics function result, overall and by groups:
```{r eval = FALSE , results = "hide" }
this_result <-
	sbo_MIcombine( sbo_with( sbo_design ,
		svymean( ~ receipts_noisy )
	) )

coef( this_result )
SE( this_result )
confint( this_result )
cv( this_result )

grouped_result <-
	sbo_MIcombine( sbo_with( sbo_design ,
		svyby( ~ receipts_noisy , ~ gender_ownership , svymean )
	) )

coef( grouped_result )
SE( grouped_result )
confint( grouped_result )
cv( grouped_result )
```

Calculate the degrees of freedom of any survey design object:
```{r eval = FALSE , results = "hide" }
sbo_degf( sbo_design )
```

Calculate the complex sample survey-adjusted variance of any statistic:
```{r eval = FALSE , results = "hide" }
sbo_MIcombine( sbo_with( sbo_design , svyvar( ~ receipts_noisy ) ) )
```

Include the complex sample design effect in the result for a specific statistic:
```{r eval = FALSE , results = "hide" }
# SRS without replacement
sbo_MIcombine( sbo_with( sbo_design ,
	svymean( ~ receipts_noisy , deff = TRUE )
) )

# SRS with replacement
sbo_MIcombine( sbo_with( sbo_design ,
	svymean( ~ receipts_noisy , deff = "replace" )
) )
```

Compute confidence intervals for proportions using methods that may be more accurate near 0 and 1. See `?svyciprop` for alternatives:
```{r eval = FALSE , results = "hide" }
# # sbo_MIsvyciprop( ~ established_before_2000 , sbo_design ,
# 	method = "likelihood" , na.rm = TRUE )
```

### Regression Models and Tests of Association {-}

Perform a design-based t-test:
```{r eval = FALSE , results = "hide" }
# # sbo_MIsvyttest( receipts_noisy ~ established_before_2000 , sbo_design )
```

Perform a chi-squared test of association for survey data:
```{r eval = FALSE , results = "hide" }
# # sbo_MIsvychisq( ~ established_before_2000 + n07_employer , sbo_design )
```

Perform a survey-weighted generalized linear model:
```{r eval = FALSE , results = "hide" }
glm_result <- 
	sbo_MIcombine( sbo_with( sbo_design ,
		svyglm( receipts_noisy ~ established_before_2000 + n07_employer )
	) )
	
glm_result
```

---

## Intermish {-}

<center>https://en.wikipedia.org/wiki/Lorem_ipsum</center>

---

## Replication Example {-}

```{r eval = FALSE , results = "hide" }

hispanic_receipts_result <- sbo_MIcombine( sbo_with( sbo_design , svyby( ~ receipts_noisy , ~ hispanic_ownership , svytotal ) ) )

stopifnot( round( coef( hispanic_receipts_result )[ 'hispanic' ] , 0 ) == 350763923 )
stopifnot( round( coef( hispanic_receipts_result )[ 'equally hispanic/non-hispanic' ] , 0 ) == 56166354 )
stopifnot( round( coef( hispanic_receipts_result )[ 'non-hispanic' ] , 0 ) == 10540609303 )

stopifnot( round( cv( hispanic_receipts_result )[ 'hispanic' ] , 2 ) == 0.02 )
stopifnot( round( cv( hispanic_receipts_result )[ 'equally hispanic/non-hispanic' ] , 2 ) == 0.06 )
stopifnot( round( cv( hispanic_receipts_result )[ 'non-hispanic' ] , 2 ) == 0 )

hispanic_payroll_result <- sbo_MIcombine( sbo_with( sbo_design , svyby( ~ payroll_noisy , ~ hispanic_ownership , svytotal ) ) )

stopifnot( round( coef( hispanic_payroll_result )[ 'hispanic' ] , 0 ) == 54367702 )
stopifnot( round( coef( hispanic_payroll_result )[ 'equally hispanic/non-hispanic' ] , 0 ) == 11083148 )
stopifnot( round( coef( hispanic_payroll_result )[ 'non-hispanic' ] , 0 ) == 1875353228 )

stopifnot( round( cv( hispanic_payroll_result )[ 'hispanic' ] , 2 ) == 0.01 )
stopifnot( round( cv( hispanic_payroll_result )[ 'equally hispanic/non-hispanic' ] , 2 ) == 0.06 )
stopifnot( round( cv( hispanic_payroll_result )[ 'non-hispanic' ] , 2 ) == 0 )

hispanic_employment_result <- sbo_MIcombine( sbo_with( sbo_design , svyby( ~ employment_noisy , ~ hispanic_ownership , svytotal ) ) )

stopifnot( round( coef( hispanic_employment_result )[ 'hispanic' ] , 0 ) == 2026406 )
stopifnot( round( coef( hispanic_employment_result )[ 'equally hispanic/non-hispanic' ] , 0 ) == 400152 )
stopifnot( round( coef( hispanic_employment_result )[ 'non-hispanic' ] , 0 ) == 56889606 )

stopifnot( round( cv( hispanic_employment_result )[ 'hispanic' ] , 2 ) == 0.01 )
stopifnot( round( cv( hispanic_employment_result )[ 'equally hispanic/non-hispanic' ] , 2 ) == 0.05 )
stopifnot( round( cv( hispanic_employment_result )[ 'non-hispanic' ] , 2 ) == 0 )

```


