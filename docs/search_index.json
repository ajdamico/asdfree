[["index.html", "Analyze Survey Data for Free Public Microdata, Easy to Type Website", " Analyze Survey Data for Free Public Microdata, Easy to Type Website Please ask questions about the content of this book at stackoverflow.com with the R and survey tags. The survey microdata presented in this book require the R survey package by Dr. Thomas Lumley at the University of Auckland. Dr. Lumley wrote a textbook to showcase that software. This book replaces my archived blog, prior code, and the no longer maintained lodown package. A work of R is never finished, only abandoned. - Anthony Damico "],["american-community-survey-acs.html", "American Community Survey (ACS) Simplified Download and Importation Analysis Examples with the survey library   Poverty and Inequality Estimation with convey   Replication Example", " American Community Survey (ACS) The US Census Bureau’s annual replacement for the long-form decennial census. One table with one row per household and a second table with one row per individual within each household. The civilian population of the United States. Released annually since 2005. Administered and financed by the US Census Bureau. Simplified Download and Importation The R lodown package easily downloads and imports all available ACS microdata by simply specifying \"acs\" with an output_dir = parameter in the lodown() function. Depending on your internet connection and computer processing speed, you might prefer to run this step overnight. library(lodown) lodown( &quot;acs&quot; , output_dir = file.path( path.expand( &quot;~&quot; ) , &quot;ACS&quot; ) ) lodown also provides a catalog of available microdata extracts with the get_catalog() function. After requesting the ACS catalog, you could pass a subsetted catalog through the lodown() function in order to download and import specific extracts (rather than all available extracts). library(lodown) # examine all available ACS microdata files acs_cat &lt;- get_catalog( &quot;acs&quot; , output_dir = file.path( path.expand( &quot;~&quot; ) , &quot;ACS&quot; ) ) # 2016 alabama single-year only. remove ` &amp; stateab == &#39;al&#39;` for a nationwide table acs_cat &lt;- subset( acs_cat , year == 2016 &amp; time_period == &#39;1-Year&#39; &amp; stateab == &#39;al&#39; ) # download the microdata to your local computer acs_cat &lt;- lodown( &quot;acs&quot; , acs_cat ) Analysis Examples with the survey library   Construct a complex sample survey design: # # alternative subsets: # # nationwide merged table including puerto rico # acs_cat &lt;- subset( acs_cat , year == 2016 &amp; time_period == &#39;1-Year&#39; ) # acs_cat &lt;- lodown( &quot;acs&quot; , acs_cat ) # # nationwide merged table excluding puerto rico # acs_cat &lt;- subset( acs_cat , year == 2016 &amp; time_period == &#39;1-Year&#39; &amp; stateab != &#39;pr&#39; ) # acs_cat &lt;- lodown( &quot;acs&quot; , acs_cat ) library(survey) acs_df &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;ACS&quot; , &quot;acs2016_1yr.rds&quot; ) ) # because of the catalog subset above # the `merged.rds` file is alabama only acs_design &lt;- svrepdesign( weight = ~pwgtp , repweights = &#39;pwgtp[0-9]+&#39; , scale = 4 / 80 , rscales = rep( 1 , 80 ) , mse = TRUE , type = &#39;JK1&#39; , data = acs_df ) Variable Recoding Add new columns to the data set: acs_design &lt;- update( acs_design , relp = as.numeric( relp ) , state_name = factor( as.numeric( st ) , levels = c(1L, 2L, 4L, 5L, 6L, 8L, 9L, 10L, 11L, 12L, 13L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L, 53L, 54L, 55L, 56L, 72L) , labels = c(&quot;Alabama&quot;, &quot;Alaska&quot;, &quot;Arizona&quot;, &quot;Arkansas&quot;, &quot;California&quot;, &quot;Colorado&quot;, &quot;Connecticut&quot;, &quot;Delaware&quot;, &quot;District of Columbia&quot;, &quot;Florida&quot;, &quot;Georgia&quot;, &quot;Hawaii&quot;, &quot;Idaho&quot;, &quot;Illinois&quot;, &quot;Indiana&quot;, &quot;Iowa&quot;, &quot;Kansas&quot;, &quot;Kentucky&quot;, &quot;Louisiana&quot;, &quot;Maine&quot;, &quot;Maryland&quot;, &quot;Massachusetts&quot;, &quot;Michigan&quot;, &quot;Minnesota&quot;, &quot;Mississippi&quot;, &quot;Missouri&quot;, &quot;Montana&quot;, &quot;Nebraska&quot;, &quot;Nevada&quot;, &quot;New Hampshire&quot;, &quot;New Jersey&quot;, &quot;New Mexico&quot;, &quot;New York&quot;, &quot;North Carolina&quot;, &quot;North Dakota&quot;, &quot;Ohio&quot;, &quot;Oklahoma&quot;, &quot;Oregon&quot;, &quot;Pennsylvania&quot;, &quot;Rhode Island&quot;, &quot;South Carolina&quot;, &quot;South Dakota&quot;, &quot;Tennessee&quot;, &quot;Texas&quot;, &quot;Utah&quot;, &quot;Vermont&quot;, &quot;Virginia&quot;, &quot;Washington&quot;, &quot;West Virginia&quot;, &quot;Wisconsin&quot;, &quot;Wyoming&quot;, &quot;Puerto Rico&quot;) ) , cit = factor( cit , levels = 1:5 , labels = c( &#39;born in the u.s.&#39; , &#39;born in the territories&#39; , &#39;born abroad to american parents&#39; , &#39;naturalized citizen&#39; , &#39;non-citizen&#39; ) ) , poverty_level = as.numeric( povpip ) , married = as.numeric( mar %in% 1 ) , sex = factor( sex , labels = c( &#39;male&#39; , &#39;female&#39; ) ) ) Unweighted Counts Count the unweighted number of records in the survey sample, overall and by groups: sum( weights( acs_design , &quot;sampling&quot; ) != 0 ) svyby( ~ one , ~ cit , acs_design , unwtd.count ) Weighted Counts Count the weighted size of the generalizable population, overall and by groups: svytotal( ~ one , acs_design ) svyby( ~ one , ~ cit , acs_design , svytotal ) Descriptive Statistics Calculate the mean (average) of a linear variable, overall and by groups: svymean( ~ poverty_level , acs_design , na.rm = TRUE ) svyby( ~ poverty_level , ~ cit , acs_design , svymean , na.rm = TRUE ) Calculate the distribution of a categorical variable, overall and by groups: svymean( ~ sex , acs_design ) svyby( ~ sex , ~ cit , acs_design , svymean ) Calculate the sum of a linear variable, overall and by groups: svytotal( ~ poverty_level , acs_design , na.rm = TRUE ) svyby( ~ poverty_level , ~ cit , acs_design , svytotal , na.rm = TRUE ) Calculate the weighted sum of a categorical variable, overall and by groups: svytotal( ~ sex , acs_design ) svyby( ~ sex , ~ cit , acs_design , svytotal ) Calculate the median (50th percentile) of a linear variable, overall and by groups: svyquantile( ~ poverty_level , acs_design , 0.5 , na.rm = TRUE ) svyby( ~ poverty_level , ~ cit , acs_design , svyquantile , 0.5 , ci = TRUE , keep.var = TRUE , na.rm = TRUE ) Estimate a ratio: svyratio( numerator = ~ ssip , denominator = ~ pincp , acs_design , na.rm = TRUE ) Subsetting Restrict the survey design to senior citizens: sub_acs_design &lt;- subset( acs_design , agep &gt;= 65 ) Calculate the mean (average) of this subset: svymean( ~ poverty_level , sub_acs_design , na.rm = TRUE ) Measures of Uncertainty Extract the coefficient, standard error, confidence interval, and coefficient of variation from any descriptive statistics function result, overall and by groups: this_result &lt;- svymean( ~ poverty_level , acs_design , na.rm = TRUE ) coef( this_result ) SE( this_result ) confint( this_result ) cv( this_result ) grouped_result &lt;- svyby( ~ poverty_level , ~ cit , acs_design , svymean , na.rm = TRUE ) coef( grouped_result ) SE( grouped_result ) confint( grouped_result ) cv( grouped_result ) Calculate the degrees of freedom of any survey design object: degf( acs_design ) Calculate the complex sample survey-adjusted variance of any statistic: svyvar( ~ poverty_level , acs_design , na.rm = TRUE ) Include the complex sample design effect in the result for a specific statistic: # SRS without replacement svymean( ~ poverty_level , acs_design , na.rm = TRUE , deff = TRUE ) # SRS with replacement svymean( ~ poverty_level , acs_design , na.rm = TRUE , deff = &quot;replace&quot; ) Compute confidence intervals for proportions using methods that may be more accurate near 0 and 1. See ?svyciprop for alternatives: svyciprop( ~ married , acs_design , method = &quot;likelihood&quot; ) Regression Models and Tests of Association Perform a design-based t-test: svyttest( poverty_level ~ married , acs_design ) Perform a chi-squared test of association for survey data: svychisq( ~ married + sex , acs_design ) Perform a survey-weighted generalized linear model: glm_result &lt;- svyglm( poverty_level ~ married + sex , acs_design ) summary( glm_result ) Poverty and Inequality Estimation with convey   The R convey library estimates measures of income concentration, poverty, inequality, and wellbeing. This textbook details the available features. As a starting point for ACS users, this code calculates the gini coefficient on complex sample survey data: library(convey) acs_design &lt;- convey_prep( acs_design ) svygini( ~ hincp , acs_design , na.rm = TRUE ) Replication Example The example below matches statistics, standard errors, and margin of errors from this table pulled from the tallies of 2016 PUMS: Match the sum of the weights: stopifnot( round( coef( svytotal( ~ one , acs_design ) ) , 0 ) == 4863300 ) Compute the population by age: pums_estimate &lt;- c( 285681 , 314701 , 300814 , 334318 , 327896 , 629329 , 599719 , 644212 , 342205 , 300254 , 464893 , 231293 , 87985 ) pums_standard_error &lt;- c( 2888 , 5168 , 5009 , 3673 , 3521 , 4825 , 4088 , 4398 , 5329 , 5389 , 1938 , 3214 , 2950 ) pums_margin_of_error &lt;- c( 4751 , 8501 , 8240 , 6043 , 5792 , 7937 , 6725 , 7234 , 8767 , 8865 , 3188 , 5287 , 4853 ) results &lt;- svytotal( ~ as.numeric( agep %in% 0:4 ) + as.numeric( agep %in% 5:9 ) + as.numeric( agep %in% 10:14 ) + as.numeric( agep %in% 15:19 ) + as.numeric( agep %in% 20:24 ) + as.numeric( agep %in% 25:34 ) + as.numeric( agep %in% 35:44 ) + as.numeric( agep %in% 45:54 ) + as.numeric( agep %in% 55:59 ) + as.numeric( agep %in% 60:64 ) + as.numeric( agep %in% 65:74 ) + as.numeric( agep %in% 75:84 ) + as.numeric( agep %in% 85:100 ) , acs_design ) stopifnot( all( round( coef( results ) , 0 ) == pums_estimate ) ) stopifnot( all( round( SE( results ) , 0 ) == pums_standard_error ) ) stopifnot( all( round( SE( results ) * 1.645 , 0 ) == pums_margin_of_error ) ) "],["balancing-respondent-confidentiality-with-variance-estimation-precision.html", "Balancing Respondent Confidentiality with Variance Estimation Precision", " Balancing Respondent Confidentiality with Variance Estimation Precision # analyze survey data for free (http://asdfree.com) with the r language # how to create de-identified replicate weights # in less than ten steps # anthony joseph damico # ajdamico@gmail.com # the institute for digital research and education at ucla # hosts a very readable explanation of replicate weights, # how they protect confidentiality, and why they&#39;re generally awesome # http://www.ats.ucla.edu/stat/stata/library/replicate_weights.htm # remove the # in order to run this install.packages line only once # install.packages( c( &quot;survey&quot; , &quot;sdcMicro&quot; ) ) # load the r survey package library(survey) # load the sdcMicro package library(sdcMicro) # load some sample complex sample survey data data(api) # look at the first six records of the `apistrat` data.frame object # so you have a sense of what you&#39;re working with in this example # this particular example is student performance in california schools # http://r-survey.r-forge.r-project.org/survey/html/api.html head( apistrat ) ########################################### # # # # # # # # # # # # # # # # # # # # # # # part one. create the replicate weights # # # # # # # # # # # # # # # # # # # # # # # ########################################### # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # step one: construct the taylor-series linearized design # # that you use on your internal, confidential microdata # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # there are many permutations of linearized designs. # you can find well-documented examples of tsl design setups # by searching for the text `svydesign` here: # https://github.com/ajdamico/asdfree/search?q=svydesign&amp;ref=cmdform # does your tsl design have a strata argument? # # this design does not have a `strata=` parameter api.tsl.without.strata &lt;- svydesign( id = ~dnum , data = apistrat , weights = ~pw ) # this design does have a `strata=` parameter api.tsl.with.strata &lt;- svydesign( id = ~dnum , strata = ~stype , data = apistrat , weights = ~pw , nest = TRUE ) # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # step two: convert this taylor-series linearized design # # to one of a few choices of replication-based designs # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # for unstratified designs, # use a &quot;jackknife delete one&quot; method api.jk1 &lt;- as.svrepdesign( api.tsl.without.strata , type = &quot;JK1&quot; , fay.rho = 0.5 , mse = TRUE , compress = FALSE # note: compressed replicate weights require less RAM but complicate the weight-extraction in step three ) # for stratified designs, # you might first attempt to use a # balanced repeated replication method # with a fay&#39;s adjustment # (this is the most common setup from the united states census bureau) try( { api.fay &lt;- as.svrepdesign( api.tsl.with.strata , type = &quot;Fay&quot; , fay.rho = 0.5 , mse = TRUE , compress = FALSE # note: compressed replicate weights require less RAM but complicate the weight-extraction in step three ) } , silent = TRUE ) # however, if the sampling plan contains an # odd number of clusters within any stratum # you will hit this error # Error in brrweights(design$strata[, 1], design$cluster[, 1], ..., fay.rho = fay.rho, : # Can&#39;t split with odd numbers of PSUs in a stratum # for stratified designs with an # odd number of clusters in any stratum, # use a &quot;jackknife delete n&quot; method api.jkn &lt;- as.svrepdesign( api.tsl.with.strata , type = &quot;JKn&quot; , mse = TRUE , compress = FALSE # note: compressed replicate weights require less RAM but complicate the weight-extraction in step three ) # now you have a matrix of replicate weights # stored in your replication-based survey-design # the purpose of this exercise is to produce comparable # variance estimates without compromising confidentiality # therefore, run a few standard error calculations # using the original linearized designs, # compared to the newly-created jackknife design # calculate the mean 1999 and 2000 academic performance index scores # using the original stratified taylor-series design.. svymean( ~ api99 + api00 , api.tsl.with.strata ) # ..and the newly-created jackknife replication-based design svymean( ~ api99 + api00 , api.jkn ) # the standard errors for these estimates are nearly identical # # run the same commands as above, broken down by award program eligibility svyby( ~ api99 + api00 , ~ awards , api.tsl.with.strata , svymean ) svyby( ~ api99 + api00 , ~ awards , api.jkn , svymean ) # in each case, the replication-based design # (that we created off of the linearized design) # produced a comparable variance estimate # # # # # # # # # # # # # # # # # # # # # # # # # # step three: extract the replication weights # # from your newly created survey design object # # # # # # # # # # # # # # # # # # # # # # # # # # # note that this example shows how to extract # the weights from the `api.jkn` survey object # however, this method would be identical # for the `api.jk1` and `api.fay` objects # displayed above as well # despite `api.fay` throwing an error, # because of an uneven number of clusters within strata # look at your survey design api.jkn # look at the contents of your replication-based survey design names( api.jkn ) # look at the first six replicate weight records within your survey design head( api.jkn$repweights ) # note that these weights are not *combined* by default # in other words, they still need to be multiplied by the original weight # you can confirm this by looking at the flag that indicates: # &quot;have replicate weights been combined?&quot; api.jkn$combined.weights # no. they have not been combined # therefore, these replication weights are `uncombined` # and will need to be analyzed by the user as such your.replicate.weights &lt;- data.frame( unclass( api.jkn$repweights ) ) # # # # # # # # # # # # # # # # # # # # # # # # # you&#39;ve created the set of replicate-weights # ############################################# # # # # # # # # # # # # # # # # # # # # # # # # part two. mask the strata from evil users # # # # # # # # # # # # # # # # # # # # # # # # ############################################# # now prevent users from reidentifying strata # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # step four: understand how a malicious user might easily # # identify clustering variables on un-obfuscated data # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # start with the replicate weights object from the script transposed.rw &lt;- data.frame( t( your.replicate.weights ) ) # the first record of apistrat has dnum==401 and stype==&#39;E&#39; # going back to the original microdata set, # eleven records are in this cluster x stratum which( apistrat$dnum == 401 &amp; apistrat$stype == &#39;E&#39; ) # without massaging your replicate weights at all, # a malicious user could easily view the correlations # between each record&#39;s replicate weights # in order to determine what other records # land in the same cluster x strata # for example, here are all replicate-weight records that # perfectly (after rounding) correlate with # the first record. which( round( cor( transposed.rw )[ 1 , ] ) == 1 ) # same numbers! # (wikipedia has a great definition: http://en.wikipedia.org/wiki/Obfuscation) # if you do not obfuscate your data, a malicious user could # identify unique clusters and strata even if only given replicate weights # # # # # # # # # # # # # # # # # step five: BRING THE NOISE # # # # # # # # # # # # # # # # # # set a random seed. this allows you to # go back to this code and reproduce the # exact same results in the future. # the following steps include a random process # setting a seed enforces the same random process every time sum( utf8ToInt( &quot;anthony is cool&quot; ) ) # my current favorite number is 1482, so let&#39;s go with that. set.seed( 1482 ) # figure out how much noise to add. noisy.transposed.rw &lt;- addNoise( transposed.rw , noise = 1 )$xm # remember, on the original replicate weight objects, # the correlations between the first record and # other records within the same clusters and strata # were perfect. which( sapply( cor( transposed.rw )[ 1 , ] , function( z ) isTRUE( all.equal( z , 1 ) ) ) ) # run the same test on noisified weights which( sapply( cor( noisy.transposed.rw )[ 1 , ] , function( z ) isTRUE( all.equal( z , 1 ) ) ) ) # and suddenly none of the other records are perfectly correlated # but even moderately correlations might allow evildoers # to identify clusters and strata # these records have a 0.1 or higher correlation coefficient which( cor( noisy.transposed.rw )[ 1 , ] &gt; 0.1 ) # these records have a 0.2 or higher correlation coefficient which( cor( noisy.transposed.rw )[ 1 , ] &gt; 0.2 ) # whoops. we did not add enough noise. # records in the same cluster x strata still have # too high of a correlation coefficient, # relative to other records # okay. this will make a big difference # on the size of the standard errors that # your users will actually see. # make a clutch decision: # how much noise can you tolerate? # hmncyt &lt;- 1 hmncyt &lt;- 3 # hmncyt &lt;- 10 # you need to run this script a few times # because the size of your standard errors # are going to change, depending on your data set. # essentially, choose the lowest noise value # that does not lead you to uncomfortable levels # of correlation within cluster/strata # in your replicate weights columns # crank up the random noise percentage to three noisy.transposed.rw &lt;- addNoise( transposed.rw , noise = hmncyt )$xm # and suddenly.. # records 29, 73 and 158 have a correlation coefficient # that&#39;s greater than zero point two. which( cor( noisy.transposed.rw )[ 1 , ] &gt; 0.2 ) # and of those, only record #29 is in the same cluster x strata intersect( which( cor( noisy.transposed.rw )[ 1 , ] &gt; 0.2 ) , which( round( cor( transposed.rw )[ 1 , ] ) == 1 ) ) # that&#39;s awesome, because you have two false-positives here. # the &quot;73&quot; and &quot;158&quot; will throw off a malicious user. # these records have a 0.1 or higher correlation coefficient which( cor( noisy.transposed.rw )[ 1 , ] &gt; 0.1 ) # and that looks very good. # because less than half of those records # are actually in the same cluster x strata intersect( which( cor( noisy.transposed.rw )[ 1 , ] &gt; 0.1 ) , which( round( cor( transposed.rw )[ 1 , ] ) == 1 ) ) # and there are lots of other records with high correlations (false positives) # that in fact are not in the same strata. great. perf. magnifique! # this object `noisy.transposed.rw` is the set of replicate weights # that you might now feel comfortable disclosing to your users. # bee tee dubs # you should un-transpose the weights rightaboutnow noisy.rw &lt;- t( noisy.transposed.rw ) # # # # # # # # # # # # # # # # # # # # # # step six: check with your legal dept. # # # # # # # # # # # # # # # # # # # # # # # brilliant malicious users might still be able to identify certain records # if they work really really really hard and have access to other information # included in your survey microdata set. # for example: # if your technical documentation says that memphis was one of your sampled clusters, and # if your microdata does have a state identifier, and # if the content of your survey was about barbeque consumption # it&#39;s possible that no amount of masking, obfuscating, massaging, noising, whathaveyouing # will prevent malicious users from determining the geography of some of the records # included in your public use file. so don&#39;t mindlessly follow this example. # consider exactly what you&#39;re disclosing, consider how someone might use it improperly. # # # # # # # # # # # # # # # # # # # # # # # # you&#39;ve protected cluster confidentiality # ############################################# # # # # # # # # # # # # # # # # # # # # # # # # part three. share these replicate weights # # # # # # # # # # # # # # # # # # # # # # # # ############################################# # now share these weights with your users. # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # step seven: remove the confidential fields from your data # # and tack on the replicate weight columns created above. # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # go back to our original data.frame object `apistrat` # and store that entire table into `x` x &lt;- apistrat # remove the columns that were deemed too confidential to release x$dnum &lt;- x$stype &lt;- NULL # in other words, delete the cluster and strata variables # from this data.frame object so you have a &quot;safe-for-the-public&quot; data set # look at the first six records # to confirm they have been removed head( x ) # merge on the replicate weight data.frame # that we just created, which contains # obfuscated-confidential information for users y &lt;- cbind( x , noisy.rw ) # look at the first six records # to confirm the weights have been tacked on head( y ) # the replicate weights are now stored # as `X1` through `X162` # this data.frame object `y` # contains all of the information that # a user needs to correctly calculate a # variance, standard error, confidence interval # uncomment this line to # export `y` to a csv file # write.csv( y , &quot;C:/My Directory/your microdata.csv&quot; ) # this csv file contains your full microdata set, # except for the cluster and strata variables # that you had determined to be confidential information # in other words, now you&#39;ve got a public-use file (puf) # that no longer contains identifiable geographic information # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # step eight: determine the `svrepdesign` specification to # # match the survey object above, but without cluster info # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # once users have a copy of this de-identified # microdata file, they will need the # replication-based complex sample design # there are many permutations of replication-based designs. # you can find well-documented examples of replicate weighted design setups # by searching for the text `svrepdesign` here: # https://github.com/ajdamico/asdfree/search?q=svrepdesign&amp;type=Code # for the object `y` built above, # construct the replication-based # &quot;jackknife delete n&quot; method # complex sample survey design object z &lt;- svrepdesign( data = y , type = &quot;JKn&quot; , repweights = &quot;X[1-9]+&quot; , weights = ~pw , scale = 1 , combined.weights = FALSE , mse = TRUE ) # is it giving you a warning about calculating the rscales by itself? # good. then you&#39;re doing right by me. # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # step nine: confirm this new replication survey object # # matches the standard errors derived from as.svrepdesign # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # this `z` object can now be analyzed # and the statistics but not the standard errors # will match the `api.jkn` shown above. svymean( ~ api99 + api00 , z ) svymean( ~ api99 + api00 , api.jkn ) svyby( ~ api99 + api00 , ~ awards , z , svymean ) svyby( ~ api99 + api00 , ~ awards , api.jkn , svymean ) # see how the standard errors have a-little-more-than-doubled? # that&#39;s because we had to BRING THE NOISE to the replicate weights # if you re-run this script but lower the value of `hmncyt` # your standard errors will *decrease* and get closer to # what they actually are when you have the confidential information. # that&#39;s the trade-off. re-run this entire script but set `hmncyt &lt;- 0` # and you&#39;ll see some almost-perfect standard errors.. # but doing that would allow malicious users to identify clusters easily # then re-run it again and set `hmncyt &lt;- 10` and suddenly # no way in hell can a malicious user identify clustering information # but your standard errors (and subsequent confidence intervals) are ginormous # obfuscating your replicate weights is going to make it harder for users # to detect statistically significant differences when analyzing your microdata. # no way around that. # just do your best to minimize the amount of obfuscation. # dooooo it. public use microdata are an indisputable good. "],["structural-equation-models-sem-with-complex-survey-data.html", "Structural Equation Models (SEM) with Complex Survey Data Load the 2008 Wave of the European Social Survey German and Spanish Microdata Two-factor CFA of attitudes toward the welfare state Invariance testing on Schwarz human values while accounting for the survey design. An example with a Latent Variable Regression", " Structural Equation Models (SEM) with Complex Survey Data Contributed by Dr. Daniel Oberski &lt;daniel.oberski@gmail.com&gt; The R lavaan.survey package by Dr. Daniel Oberski fits structural equation models to complex survey microdata, described in his JSS article. install.packages( &quot;lavaan.survey&quot; , repos = &quot;http://cran.rstudio.com/&quot; ) Load the 2008 Wave of the European Social Survey German and Spanish Microdata library(lodown) library(lavaan.survey) options( survey.lonely.psu = &quot;adjust&quot; ) # retrieve a listing of all available extracts for the european social survey ess_cat &lt;- get_catalog( &quot;ess&quot; , output_dir = file.path( path.expand( &quot;~&quot; ) , &quot;ESS&quot; ) ) # limit the catalog to only wave #4 for germany and spain ess_cat &lt;- subset( ess_cat , wave == 4 &amp; grepl( &quot;c=DE|c=ES&quot; , full_url ) ) # download the ess microdata lodown( &quot;ess&quot; , ess_cat , your_email = &quot;email@address.com&quot; ) Immediately pull the German files into the workspace: # load Germany&#39;s round four main data file.. ess4.de &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;ESS&quot; , &quot;2008/ESS4DE.rds&quot; ) ) # load Germany&#39;s round four sample design data file (sddf).. ess4.de.sddf &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;ESS&quot; , &quot;2008/ESS4_DE_SDDF.rds&quot; ) ) The stratify variable is not literally equal to the actual strata but contains more information (which we don’t need here). Create a new variable that only uses the actual stratification namely, East v. West Germany, by using a regular expression / string substitution function to take the data.frame object’s stratify variable, convert it to a character variable, search for a dash, and keep only the text before the dash. Then, convert that resultant vector of ones and twos into a factor variable, labeled East versus West Germany. ess4.de.sddf$stratify &lt;- factor( gsub( &quot;(\\\\d+)-.+&quot; , &quot;\\\\1&quot; , as.character( ess4.de.sddf$stratify ) ) ) levels(ess4.de.sddf$stratify) &lt;- c(&quot;West Germany&quot;, &quot;East Germany&quot;) Check against ESS documentation statement that “The number of sampling points is 109 in the West, and 59 in the East”: stopifnot(tapply(ess4.de.sddf$psu, ess4.de.sddf$stratify, function(x) length(unique(x))) == c(109, 59)) Merge these two files together, creating a single table: ess4.de.m &lt;- merge( ess4.de , ess4.de.sddf) stopifnot( nrow( ess4.de ) == nrow( ess4.de.m ) &amp; nrow( ess4.de.sddf ) == nrow( ess4.de.m ) ) Create a survey design object: ess4.de.design &lt;- svydesign( ids = ~psu , strata = ~stratify , probs = ~prob , data = ess4.de.m ) Two-factor CFA of attitudes toward the welfare state This analysis uses the model of the below article. Please see the article for more information. Roosma, F., Gelissen, J., &amp; van Oorschot, W. (2013). The multidimensionality of welfare state attitudes: a European cross-national study. Social indicators research, 113(1), 235-255. Formulate the two-factor CFA using lavaan syntax: model.cfa &lt;- &quot;range =~ gvjbevn + gvhlthc + gvslvol + gvslvue + gvcldcr + gvpdlwk goals =~ sbprvpv + sbeqsoc + sbcwkfm&quot; Fit the model using lavaan, accounting for possible nonnormality using the MLM estimator: fit.cfa.ml &lt;- lavaan( model.cfa , data = ess4.de.m , estimator = &quot;MLM&quot; , int.ov.free = TRUE , auto.var = TRUE , auto.fix.first = TRUE , auto.cov.lv.x = TRUE ) Show some fit measure results, note the “scaling correction” which accounts for nonnormality: fit.cfa.ml Fit the two-factor model while taking the survey design into account: fit.cfa.surv &lt;- lavaan.survey( fit.cfa.ml , survey.design = ess4.de.design ) Show some fit measure results, “scaling correction” now accounts for both nonnormality and survey design. fit.cfa.surv Display parameter estimates and standard errors accounting for survey design: summary( fit.cfa.surv , standardized = TRUE ) Invariance testing on Schwarz human values while accounting for the survey design. For more information on this analysis, see: Davidov, E., Schmidt, P., &amp; Schwartz, S. H. (2008). “Bringing values back in: The adequacy of the European Social Survey to measure values in 20 countries”. Public opinion quarterly, 72(3), 420-445. Test the measurement equivalence of Schwarz human values from round 4 of the ESS, comparing Germany with Spain. First load the Spanish data so these can be merged: # load Spain&#39;s round four main data file.. ess4.es &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;ESS&quot; , &quot;2008/ESS4ES.rds&quot; ) ) # load Spain&#39;s round four sample design data file (sddf).. ess4.es.sddf &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;ESS&quot; , &quot;2008/ESS4_ES_SDDF.rds&quot; ) ) Merge these two files together, creating a single table: ess4.es.m &lt;- merge( ess4.es , ess4.es.sddf) stopifnot( nrow( ess4.es ) == nrow( ess4.es.m ) &amp; nrow( ess4.es.sddf ) == nrow( ess4.es.m ) ) Make sure PSU names are unique between the two countries. Paste on a “de-” to the German PSUs, and by pasting an “es-” to the front of the Spanish PSUs. ess4.de.m$psu &lt;- paste( &quot;de&quot; , ess4.de.m$psu , sep=&quot;-&quot; ) ess4.es.m$psu &lt;- paste( &quot;es&quot; , ess4.es.m$psu , sep=&quot;-&quot; ) Stack the two countries into a single table, then construct a survey design: ess4.m &lt;- rbind( ess4.de.m , ess4.es.m ) ess4.design &lt;- svydesign( ids = ~psu, strata = ~stratify , probs = ~prob , data = ess4.m ) Model based on Schwarz human value theory. Note that this is the basic starting model, not the final model used by Davidov et al. They merge certain values and allow cross-loadings: free.values.model.syntax &lt;- &quot; Universalism =~ ipeqopt + ipudrst + impenv Benevolence =~ iphlppl + iplylfr Tradition =~ ipmodst + imptrad Conformity =~ ipfrule + ipbhprp Security =~ impsafe + ipstrgv &quot; Fit two-group configural invariance model: free.values.fit &lt;- lavaan( free.values.model.syntax , data = ess4.m , auto.cov.lv.x = TRUE , auto.fix.first = TRUE , auto.var = TRUE , int.ov.free = TRUE , estimator = &quot;MLM&quot; , group = &quot;cntry&quot; ) summary( free.values.fit , standardized = TRUE ) Fit a two-group metric invariance model: free.values.fit.eq &lt;- lavaan( free.values.model.syntax , data = ess4.m , auto.cov.lv.x = TRUE , auto.fix.first = TRUE , auto.var = TRUE , int.ov.free = TRUE , estimator = &quot;MLM&quot; , group = &quot;cntry&quot; , group.equal = &quot;loadings&quot; ) summary( free.values.fit.eq , standardized = TRUE ) Metric invariance test (anova() would work here too, but not below): lavTestLRT( free.values.fit , free.values.fit.eq , SB.classic = TRUE ) Compare chisquares of the survey and non-survey SEM analyses for the configural invariance model: free.values.fit.surv &lt;- lavaan.survey( free.values.fit , ess4.design ) free.values.fit free.values.fit.surv Compare chisquares of the survey and non-survey SEM analyses for the metric invariance model: free.values.fit.eq.surv &lt;- lavaan.survey( free.values.fit.eq , ess4.design ) free.values.fit.eq free.values.fit.eq.surv Perform metric invariance test accounting for the survey design: lavTestLRT(free.values.fit.surv, free.values.fit.eq.surv, SB.classic = TRUE) The two models are more dissimilar after survey design is accounted for. An example with a Latent Variable Regression See Davidov, E., Meuleman, B., Billiet, J., &amp; Schmidt, P. (2008). Values and support for immigration: A cross-country comparison. European Sociological Review, 24(5), 583-599. The human values scale again, but this time: only two value dimensions are modeled. the two latent value dimensions are used to predict anti-immigration attitudes in the two countries. a test is performed on the difference between countries in latent regression coefficients. reg.syntax &lt;- &quot; SelfTranscendence =~ ipeqopt + ipudrst + impenv + iphlppl + iplylfr Conservation =~ ipmodst + imptrad + ipfrule + ipbhprp + impsafe + ipstrgv ALLOW =~ imdfetn + impcntr ALLOW ~ SelfTranscendence + Conservation &quot; reg.vals.fit &lt;- lavaan( reg.syntax , data = ess4.m , group = &quot;cntry&quot; , estimator = &quot;MLM&quot; , auto.cov.lv.x = TRUE , auto.fix.first = TRUE , auto.var = TRUE , int.ov.free = TRUE ) reg.vals.fit.eq &lt;- lavaan( reg.syntax , data = ess4.m , group = &quot;cntry&quot; , group.equal = &quot;regressions&quot; , estimator = &quot;MLM&quot; , auto.cov.lv.x = TRUE , auto.fix.first = TRUE , auto.var = TRUE , int.ov.free = TRUE ) summary( reg.vals.fit.eq , standardize = TRUE ) Test whether the relationship between values and anti-immigration attitudes is equal in Germany and Spain: lavTestLRT( reg.vals.fit , reg.vals.fit.eq , SB.classic = TRUE) Now do the same but accounting for the sampling design: reg.vals.fit.surv &lt;- lavaan.survey( reg.vals.fit , ess4.design ) reg.vals.fit.eq.surv &lt;- lavaan.survey( reg.vals.fit.eq , ess4.design ) lavTestLRT(reg.vals.fit.surv, reg.vals.fit.eq.surv, SB.classic = TRUE) The two models are less dissimilar after survey design is accounted for. "],["statistically-significant-trends-with-multiple-years-of-complex-survey-data.html", "Statistically Significant Trends with Multiple Years of Complex Survey Data Data Importation Load Required Packages, Options, External Functions Harmonize and Stack Multiple Years of Survey Data Construct a Multi-Year Stacked Complex Survey Design Object Review the unadjusted results Calculate the Number of Joinpoints Needed Calculate the Adjusted Prevalence and Predicted Marginals Identify the Breakpoint/Changepoint Make statistically defensible statements about linear trends with complex survey data", " Statistically Significant Trends with Multiple Years of Complex Survey Data Contributed by Thomas Yokota &lt;thomasyokota@gmail.com&gt; Palermo Professor Vito Muggeo wrote the joinpoint analysis section of the code below to demonstrate that the segmented package eliminates the need for external (registration-only, windows-only, workflow-disrupting) software. survey package creator and professor Dr. Thomas Lumley wrote the svypredmeans function to replicate SUDAAN’s PREDMARG command and match the CDC to the decimal. Dr. Richard Lowry, M.D. at the Centers for Disease Control &amp; Prevention wrote the original linear trend analysis and then answered our infinite questions. Thanks to everyone. The purpose of this analysis is to make statistically valid statements such as, “there was a significant linear decrease in the prevalence of high school aged americans who have ever smoked a cigarette across the period 1999-2011” with complex sample survey data. This step-by-step walkthrough exactly reproduces the statistics presented in the Center for Disease Control &amp; Prevention’s (CDC) linear trend analysis, using free and open source methods rather than proprietary or restricted software. The example below displays only linearized designs (created with the svydesign function). For more detail about how to reproduce this analysis with a replicate-weighted design (created with the svrepdesign function), see the methods note below section #4. Data Importation Prior to running this analysis script, the Youth Risk Behavioral Surveillance System (YRBSS) 1991-2011 single-year files must all be loaded as R data files (.rda) on your local machine. Running the download automation script will create the appropriate files. If you need assistance with the data-loading step, first review the main YRBSS blog post. options( survey.lonely.psu = &quot;adjust&quot; ) library(survey) library(lodown) # retrieve a listing of all available extracts for the youth risk behavioral surveillance system yrbss_cat &lt;- get_catalog( &quot;yrbss&quot; , output_dir = file.path( path.expand( &quot;~&quot; ) , &quot;YRBSS&quot; ) ) # limit the catalog to only years 2005-2015 yrbss_cat &lt;- subset( yrbss_cat , year %in% seq( 2005 , 2015 , 2 ) ) # download the yrbss microdata lodown( &quot;yrbss&quot; , yrbss_cat ) Load Required Packages, Options, External Functions # install.packages( c( &quot;segmented&quot; , &quot;ggplot2&quot; , &quot;ggthemes&quot; , &quot;texreg&quot; ) ) # Muggeo V. (2008) Segmented: an R package to fit regression models with broken-line relationships. R News, 8, 1: 20-25. library(segmented) library(ggplot2) library(ggthemes) library(texreg) Harmonize and Stack Multiple Years of Survey Data This step is clearly dataset-specific. In order for your trend analysis to work, you’ll need to figure out how to align the variables from multiple years of data into a trendable, stacked data.frame object. # initiate an empty `y` object y &lt;- NULL # loop through each year of YRBSS microdata for ( year in seq( 2005 , 2015 , 2 ) ){ # load the current year x &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;YRBSS&quot; , paste0( year , &quot; main.rds&quot; ) ) ) # tack on a `year` column x$year &lt;- year if( year == 2005 ) x$raceeth &lt;- NA # stack that year of data alongside the others, # ignoring mis-matching columns y &lt;- rbind( x[ c( &quot;q2&quot; , &quot;q3&quot; , &quot;q4&quot; , &quot;qn10&quot; , &quot;year&quot; , &quot;psu&quot; , &quot;stratum&quot; , &quot;weight&quot; , &quot;raceeth&quot; ) ] , y ) # clear the single-year of microdata from RAM rm( x ) } # convert every column to numeric type y[ , ] &lt;- sapply( y[ , ] , as.numeric ) # construct year-specific recodes so that # &quot;ever smoked a cigarette&quot; // grade // sex // race-ethnicity align across years y &lt;- transform( y , rode_with_drunk_driver = qn10 , raceeth = ifelse( year == 2005 , ifelse( q4 %in% 6 , 1 , ifelse( q4 %in% 3 , 2 , ifelse( q4 %in% c( 4 , 7 ) , 3 , ifelse( q4 %in% c( 1 , 2 , 5 , 8 ) , 4 , NA ) ) ) ) , ifelse( raceeth %in% 5 , 1 , ifelse( raceeth %in% 3 , 2 , ifelse( raceeth %in% c( 6 , 7 ) , 3 , ifelse( raceeth %in% c( 1 , 2 , 4 , 8 ) , 4 , NA ) ) ) ) ) , grade = ifelse( q3 == 5 , NA , as.numeric( q3 ) ) , sex = ifelse( q2 %in% 1:2 , q2 , NA ) ) # again remove unnecessary variables, keeping only the complex sample survey design columns # plus independent/dependent variables to be used in the regression analyses y &lt;- y[ c( &quot;year&quot; , &quot;psu&quot; , &quot;stratum&quot; , &quot;weight&quot; , &quot;rode_with_drunk_driver&quot; , &quot;raceeth&quot; , &quot;sex&quot; , &quot;grade&quot; ) ] # set female to the reference group y$sex &lt;- relevel( factor( y$sex ) , ref = &quot;2&quot; ) # set ever smoked=yes // white // 9th graders as the reference groups for ( i in c( &#39;rode_with_drunk_driver&#39; , &#39;raceeth&#39; , &#39;grade&#39; ) ) y[ , i ] &lt;- relevel( factor( y[ , i ] ) , ref = &quot;1&quot; ) Construct a Multi-Year Stacked Complex Survey Design Object Before constructing a multi-year stacked design object, check out ?contr.poly - this function implements polynomials used in our trend analysis during step #6. For more detail on this subject, see page 216 of Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences By Jacob Cohen, Patricia Cohen, Stephen G. West, Leona S. Aiken “The polynomials we have used as predictors to this point are natural polynomials, generated from the linear predictor by centering and the powering the linear predictor.” # extract a linear contrast vector of length eleven, # because we have eleven distinct years of yrbss data `seq( 2005 , 2015 , 2 )` c6l &lt;- contr.poly( 6 )[ , 1 ] # also extract a quadratic (squared) contrast vector c6q &lt;- contr.poly( 6 )[ , 2 ] # just in case, extract a cubic contrast vector c6c &lt;- contr.poly( 6 )[ , 3 ] # for each record in the data set, tack on the linear, quadratic, and cubic contrast value # these contrast values will serve as replacement for the linear `year` variable in any regression. # year^1 term (linear) y$t6l &lt;- c6l[ match( y$year , seq( 2005 , 2015 , 2 ) ) ] # year^2 term (quadratic) y$t6q &lt;- c6q[ match( y$year , seq( 2005 , 2015 , 2 ) ) ] # year^3 term (cubic) y$t6c &lt;- c6c[ match( y$year , seq( 2005 , 2015 , 2 ) ) ] # construct a complex sample survey design object # stacking multiple years and accounting for `year` in the nested strata des &lt;- svydesign( id = ~psu , strata = ~interaction( stratum , year ) , data = y , weights = ~weight , nest = TRUE ) Now we’ve got a multi-year stack of complex survey designs with linear, quadratic, and cubic contrast values appended. If you’d like more detail about stacking multiple years of complex survey data, review the CDC’s manual on the topic. Hopefully we won’t need anything beyond cubic, but let’s find out. Methods note about how to stack replication designs: This is only relevant if you are trying to create a des like the object above but just have replicate weights and do not have the clustering information (psu). It is straightforward to construct a replication design from a linearized design (see as.svrepdesign). However, for privacy reasons, going in the opposite direction is much more challenging. Therefore, you’ll need to do some dataset-specific homework on how to best stack multiple years of a replicate-weighted design you construct a multiple-year-stacked survey design like the object above. If you’d like to experiment with how the two approaches differ (theoretically, very little), these publicly-available survey data sets include both replicate weights and, separately, clustering information: Medical Expenditure Panel Survey National Health and Nutrition Examination Survey Consumer Expenditure Survey In most cases, omitting the year variable from the strata = ~interaction( stratum , year ) construction of des above will make your standard errors larger (conservative) -&gt; ergo -&gt; you can probably just rbind( file_with_repweights_year_one , file_with_repweights_year_two , ... ) so long as the survey design has not changed in structure over the time period that you are analyzing. Once you have the rbound replicate weights object for every year, you could just construct one huge multi-year svrepdesign object. Make sure you include scale, rscales, rho, and whatever else the svrepdesign() call asks for. If you are worried you missed something, check attributes( your_single_year_replication_design_object ). This solution is likely to be a decent approach in most cases. If you need to be very conservative with your computation of trend statistical significance, you might attempt to re-construct fake clusters for yourself using a regression. Search for “malicious” in this confidentiality explanation document. The purpose here, though, isn’t to identify individual respondents in the dataset, it’s to get a variable like psu above that gives you reasonable standard errors. Look for the object your.replicate.weights in that script. You could reconstruct a fake psu for each record in your data set with something as easy as.. # # fake_psu should be a one-record-per-person vector object # # that can immediately be appended onto your data set. # fake_psu &lt;- kmeans( your.replicate.weights , 20 ) ..where 20 is the (completely made up) number of clusters x strata. Hopefully the methodology documents (or the people who wrote them) will at least tell you how many clusters there were in the original sample, even if the clusters themselves were not disclosed. At the point you’ve made fake clusters, they will surely be worse than the real clusters (i.e. conservative standard errors) and you can construct a multiple-year survey design with: # des &lt;- svydesign( id = ~ your_fake_psus , strata = ~ year , data = y , weights = ~ weight , nest = TRUE ) This approach will probably be conservative probably. Review the unadjusted results Here’s the change over time for smoking prevalence among youth. Unadjusted prevalence rates (Figure 1) suggest a significant change in smoking prevalence. # immediately remove records with missing smoking status des_ns &lt;- subset( des , !is.na( rode_with_drunk_driver ) ) # calculate unadjusted, un-anythinged &quot;ever smoked&quot; rates by year # note that this reproduces the unadjusted &quot;ever smoked&quot; statistics at the top of # pdf page 6 of http://www.cdc.gov/healthyyouth/yrbs/pdf/yrbs_conducting_trend_analyses.pdf unadjusted &lt;- svyby( ~ rode_with_drunk_driver , ~ year , svymean , design = des_ns , vartype = c( &#39;ci&#39; , &#39;se&#39; ) ) # coerce that result into a `data.frame` object my_plot &lt;- data.frame( unadjusted ) # plot the unadjusted decline in smoking ggplot( my_plot , aes( x = year, y = rode_with_drunk_driver1 ) ) + geom_point() + geom_errorbar( aes( ymax = ci_u.rode_with_drunk_driver1 , ymin = ci_l.rode_with_drunk_driver1 ) , width = .2 ) + geom_line() + theme_tufte() + ggtitle( &quot;Figure 1. Unadjusted smoking prevalence 1999-2011&quot; ) + theme( plot.title = element_text( size = 9 , face = &quot;bold&quot; ) ) Calculate the Number of Joinpoints Needed Using the orthogonal coefficients (linear, quadratic, cubic terms) that we previously added to our data.frame object before constructing the multi-year stacked survey design, let’s now determine how many joinpoints will be needed for a trend analysis. Epidemiological models typically control for possible confounding variables such as sex and race, so let’s add them in with the linear, cubic, and quadratic year terms. Calculate the “ever smoked” binomial regression, adjusted by sex, age, race-ethnicity, and a linear year contrast. linyear &lt;- svyglm( I( rode_with_drunk_driver == 1 ) ~ sex + raceeth + grade + t6l , design = subset( des_ns , rode_with_drunk_driver %in% 1:2 ) , family = quasibinomial ) summary( linyear ) The linear year-contrast variable t11l is hugely significant here. Therefore, there is probably going to be some sort of trend. A linear trend does not need joinpoints. Not one, just zero joinpoints. If the linear term were the only significant term (out of linear, quadratic, cubic, etc.), then we would not need to calculate a joinpoint. In other words, we would not need to figure out where to best break our time trend into two, three, or even four segments. The linear trend is significant, so we should keep going. Interpretation note about segments of time: The linear term t11l was significant, so we probably have a significant linear trend somewhere to report. Now we need to figure out when that significant linear trend started and when it ended. It might be semantically true that there was a significant linear decrease in high school aged smoking over the entire period of our data 1991-2011; however, it’s inexact, unrefined to give up after only detecting a linear trend. The purpose of the following few steps is really to cordon off different time points from one another. As you’ll see later, there actually was not any detectable decrease from 1991-1999. The entirety of the decline in smoking occurred over the period from 1999-2011. So these next (methodologically tricky) steps serve to provide you and your audience with a more careful statement of statistical significance. It’s not technically wrong to conclude that smoking declined over the period of 1991-2011, it’s just verbose. Think of it as the difference between “humans first walked on the moon in the sixties” and “humans first walked on the moon in 1969” - both statements are correct, but the latter exhibits greater scientific precision. Calculate the “ever smoked” binomial regression, adjusted by sex, age, race-ethnicity, and both linear and quadratic year contrasts. Notice the addition of t11q. quadyear &lt;- svyglm( I( rode_with_drunk_driver == 1 ) ~ sex + raceeth + grade + t6l + t6q , design = subset( des_ns , rode_with_drunk_driver %in% 1:2 ) , family = quasibinomial ) summary( quadyear ) The linear year-contrast variable is hugely significant here but the quadratic year-contrast variable is also significant. Therefore, we should use joinpoint software for this analysis. A significant quadratic trend needs one joinpoint. Since both linear and quadratic terms are significant, we should move ahead and test whether the cubic term is also significant. Calculate the “ever smoked” binomial regression, adjusted by sex, age, race-ethnicity, and linear, quadratic, and cubic year contrasts. Notice the addition of t11c. cubyear &lt;- svyglm( I( rode_with_drunk_driver == 1 ) ~ sex + raceeth + grade + t6l + t6q + t6c , design = subset( des_ns , rode_with_drunk_driver %in% 1:2 ) , family = quasibinomial ) summary( cubyear ) The cubic year-contrast term is not significant in this model. Therefore, we should stop testing the shape of this line. In other words, we can stop at a quadratic trend and do not need a cubic trend. That means we can stop at a single joinpoint. Remember: a linear trend requires zero joinpoints, a quadratic trend typically requires one joinpoint, a cubic trend usually requires two, and on and on. Note: if the cubic trend were significant, then we would increase the number of joinpoints to two instead of one but since the cubic term is not significant, we should stop with the previous regression. If we keep getting significant trends, we ought to continue testing whether higher terms continue to be significant. So year^4 requires three joinpoints, year^5 requires four joinpoints, and so on. If these terms continued to be significant, we would need to return to step #4 and add additional year^n terms to the model. Just for coherence’s sake, let’s assemble all of these results into a single table where you can see the linear, quadratic, and cubic models side-by-side. The quadratic trend best describes the relationship between prevalence of smoking and change-over-time. The decision to test beyond linear trends, however, is a decision for the individual researcher to make. It is a decision that can be driven by theoretical issues, existing literature, or the availability of data. htmlreg(list(linyear , quadyear , cubyear), doctype = F, html.tag = F, inline.css = T, head.tag = F, body.tag = F, center = F, single.row = T, caption = &quot;Table 1. Testing for linear trends&quot;) Calculate the Adjusted Prevalence and Predicted Marginals First, calculate the survey-year-independent predictor effects and store these results into a separate object. marginals &lt;- svyglm( formula = I( rode_with_drunk_driver == 1 ) ~ sex + raceeth + grade , design = des_ns , family = quasibinomial ) Second, run these marginals through the svypredmeans function written by Dr. Thomas Lumley. For any archaeology fans out there, this function emulates the PREDMARG statement in the ancient language of SUDAAN. ( means_for_joinpoint &lt;- svypredmeans( marginals , ~factor( year ) ) ) Finally, clean up these results a bit in preparation for a joinpoint analysis. # coerce the results to a data.frame object means_for_joinpoint &lt;- as.data.frame( means_for_joinpoint ) # extract the row names as the survey year means_for_joinpoint$year &lt;- as.numeric( rownames( means_for_joinpoint ) ) # must be sorted, just in case it&#39;s not already means_for_joinpoint &lt;- means_for_joinpoint[ order( means_for_joinpoint$year ) , ] # rename columns so they do not conflict with variables in memory names( means_for_joinpoint ) &lt;- c( &#39;mean&#39; , &#39;se&#39; , &#39;yr&#39; ) # the above line is only because the ?segmented function (used below) # does not work if an object of the same name is also in memory. another_plot &lt;- means_for_joinpoint another_plot$ci_l.mean &lt;- another_plot$mean - (1.96 * another_plot$se) another_plot$ci_u.mean &lt;- another_plot$mean + (1.96 * another_plot$se) ggplot(another_plot, aes(x = yr, y = mean)) + geom_point() + geom_errorbar(aes(ymax = ci_u.mean, ymin = ci_l.mean), width=.2) + geom_line() + theme_tufte() + ggtitle(&quot;Figure 2. Adjusted smoking prevalence 1999-2011&quot;) + theme(plot.title = element_text(size=9, face=&quot;bold&quot;)) Identify the Breakpoint/Changepoint The original CDC analysis recommended some external software from the National Cancer Institute, which only runs on selected platforms. Dr. Vito Muggeo wrote this within-R solution using his segmented package available on CRAN. Let’s take a look at how confident we are in the value at each adjusted timepoint. Carrying out a trend analysis requires creating new weights to fit a piecewise linear regression. Figure 3 shows the relationship between variance at each datum and weighting. Larger circles display greater uncertainty and therefore lower weight. ggplot( means_for_joinpoint , aes( x = yr , y = mean ) ) + geom_point( aes( size = se ) ) + theme_tufte() + ggtitle( &quot;Figure 3. Standard Error at each timepoint\\n(smaller dots indicate greater confidence in each adjusted value)&quot; ) First, create that weight variable. means_for_joinpoint$wgt &lt;- with( means_for_joinpoint, ( mean / se ) ^ 2 ) Second, fit a piecewise linear regression. # estimate the &#39;starting&#39; linear model with the usual &quot;lm&quot; function using the log values and the weights. o &lt;- lm( log( mean ) ~ yr , weights = wgt , data = means_for_joinpoint ) Now that the regression has been structured correctly, estimate the year that our complex survey trend should be broken into two segments (the changepoint/breakpoint/joinpoint). # the segmented() function uses a random process in its algorithm. # setting the random seed ensures reproducibility set.seed( 2015 ) # add a segmented variable (`yr` in this example) with 1 breakpoint os &lt;- segmented( o , ~yr ) # `os` is now a `segmented` object, which means it includes information on the fitted model, # such as parameter estimates, standard errors, residuals. summary( os ) See the Estimated Break-Point(s) in that result? That’s the critical number from this joinpoint analysis. Note that the above number is not an integer! The R segmented package uses an iterative procedure (described in the article below) and therefore between-year solutions are returned. The joinpoint software implements two estimating algorithms: the grid-search and the Hudson algorithm. For more detail about these methods, see Muggeo V. (2003) Estimating regression models with unknown break-points. Statistics in Medicine, 22: 3055-3071.. # figuring out the breakpoint year was the purpose of this joinpoint analysis. ( your_breakpoint &lt;- round( as.vector( os$psi[, &quot;Est.&quot; ] ) ) ) # so. that&#39;s a joinpoint. that&#39;s where the two line segments join. okay? # obtain the annual percent change (APC=) estimates for each time point slope( os , APC = TRUE ) The returned CIs for the annual percent change (APC) may be different from the ones returned by NCI’s Joinpoint Software; for further details, check out Muggeo V. (2010) A Comment on `Estimating average annual per cent change in trend analysis’ by Clegg et al., Statistics in Medicine; 28, 3670-3682. Statistics in Medicine, 29, 1958-1960. This analysis returned similar results to the NCI’s Joinpoint Regression Program by estimating a changepoint at year=1999 - and, more precisely, that the start of that decreasing trend in smoking prevalence happened at an APC of -3.92 percent. That is, slope2 from the output above. Make statistically defensible statements about linear trends with complex survey data After identifying the change point for smoking prevalence, we can create two regression models (one for each time segment). (If we had two joinpoints, we would need three regression models.) The first model covers the years leading up to (and including) the changepoint (i.e., 1991 to 1999). The second model includes the years from the changepoint forward (i.e., 1999 to 2011). So start with 1991, 1993, 1995, 1997, 1999, the five year-points before (and including 1999). # calculate a five-timepoint linear contrast vector c3l &lt;- contr.poly( 3 )[ , 1 ] # tack the five-timepoint linear contrast vectors onto the current survey design object des_ns &lt;- update( des_ns , t3l = c3l[ match( year , seq( 2005 , 2009 , 2 ) ) ] ) pre_91_99 &lt;- svyglm( I( rode_with_drunk_driver == 1 ) ~ sex + raceeth + grade + t3l , design = subset( des_ns , rode_with_drunk_driver %in% 1:2 &amp; year &lt;= 2009 ) , family = quasibinomial ) summary( pre_91_99 ) Reproduce the sentence on pdf page 6 of the original document. In this example, T5L_L had a p-value=0.52261 and beta=0.03704. Therefore, there was “no significant change in the prevalence of ever smoking a cigarette during 1991-1999.” Then move on to 1999, 2001, 2003, 2005, 2007, 2009, and 2011, the seven year-points after (and including 1999). # calculate a seven-timepoint linear contrast vector c4l &lt;- contr.poly( 4 )[ , 1 ] # tack the seven-timepoint linear contrast vectors onto the current survey design object des_ns &lt;- update( des_ns , t4l = c4l[ match( year , seq( 2009 , 2015 , 2 ) ) ] ) post_99_11 &lt;- svyglm( I( rode_with_drunk_driver == 1 ) ~ sex + raceeth + grade + t4l , design = subset( des_ns , rode_with_drunk_driver %in% 1:2 &amp; year &gt;= 2009 ) , family = quasibinomial ) summary( post_99_11 ) Reproduce the sentence on pdf page 6 of the original document. In this example, T7L_R had a p-value&lt;0.0001 and beta=-0.99165. Therefore, there was a “significant linear decrease in the prevalence of ever smoking a cigarette during 1999-2011.” Note also that the 1999-2011 time period saw a linear decrease, which supports the APC estimate in step #8. Here’s everything displayed as a single coherent table. htmlreg(list(pre_91_99, post_99_11), doctype = F, html.tag = F, inline.css = T, head.tag = F, body.tag = F, center = F, single.row = T, caption = &quot;Table 2. Linear trends pre-post changepoint&quot;) This analysis may complement qualitative evaluation on prevalence changes observed from surveillance data by providing quantitative evidence, such as when a change point occurred. This analysis does not explain why or how changes in trends occur. "],["youth-risk-behavior-surveillance-system-yrbss.html", "Youth Risk Behavior Surveillance System (YRBSS) Simplified Download and Importation Analysis Examples with the survey library   Analysis Examples with srvyr   Replication Example", " Youth Risk Behavior Surveillance System (YRBSS) The Youth Risk Behavior Surveillance System is the high school edition of the Behavioral Risk Factor Surveillance System (BRFSS), a scientific study of good kids who do bad things. One table with one row per sampled youth respondent. A complex sample survey designed to generalize to all public and private school students in grades 9-12 in the United States. Released biennially since 1993. Administered by the Centers for Disease Control and Prevention. Simplified Download and Importation The R lodown package easily downloads and imports all available YRBSS microdata by simply specifying \"yrbss\" with an output_dir = parameter in the lodown() function. Depending on your internet connection and computer processing speed, you might prefer to run this step overnight. library(lodown) lodown( &quot;yrbss&quot; , output_dir = file.path( path.expand( &quot;~&quot; ) , &quot;YRBSS&quot; ) ) lodown also provides a catalog of available microdata extracts with the get_catalog() function. After requesting the YRBSS catalog, you could pass a subsetted catalog through the lodown() function in order to download and import specific extracts (rather than all available extracts). library(lodown) # examine all available YRBSS microdata files yrbss_cat &lt;- get_catalog( &quot;yrbss&quot; , output_dir = file.path( path.expand( &quot;~&quot; ) , &quot;YRBSS&quot; ) ) # 2015 only yrbss_cat &lt;- subset( yrbss_cat , year == 2015 ) # download the microdata to your local computer yrbss_cat &lt;- lodown( &quot;yrbss&quot; , yrbss_cat ) Analysis Examples with the survey library   Construct a complex sample survey design: library(survey) yrbss_df &lt;- readRDS( file.path( path.expand( &quot;~&quot; ) , &quot;YRBSS&quot; , &quot;2015 main.rds&quot; ) ) yrbss_design &lt;- svydesign( ~ psu , strata = ~ stratum , data = yrbss_df , weights = ~ weight , nest = TRUE ) Variable Recoding Add new columns to the data set: yrbss_design &lt;- update( yrbss_design , q2 = q2 , never_rarely_wore_bike_helmet = as.numeric( qn8 == 1 ) , ever_smoked_marijuana = as.numeric( qn47 == 1 ) , ever_tried_to_quit_cigarettes = as.numeric( q36 &gt; 2 ) , smoked_cigarettes_past_year = as.numeric( q36 &gt; 1 ) ) Unweighted Counts Count the unweighted number of records in the survey sample, overall and by groups: sum( weights( yrbss_design , &quot;sampling&quot; ) != 0 ) svyby( ~ one , ~ ever_smoked_marijuana , yrbss_design , unwtd.count ) Weighted Counts Count the weighted size of the generalizable population, overall and by groups: svytotal( ~ one , yrbss_design ) svyby( ~ one , ~ ever_smoked_marijuana , yrbss_design , svytotal ) Descriptive Statistics Calculate the mean (average) of a linear variable, overall and by groups: svymean( ~ bmipct , yrbss_design , na.rm = TRUE ) svyby( ~ bmipct , ~ ever_smoked_marijuana , yrbss_design , svymean , na.rm = TRUE ) Calculate the distribution of a categorical variable, overall and by groups: svymean( ~ q2 , yrbss_design , na.rm = TRUE ) svyby( ~ q2 , ~ ever_smoked_marijuana , yrbss_design , svymean , na.rm = TRUE ) Calculate the sum of a linear variable, overall and by groups: svytotal( ~ bmipct , yrbss_design , na.rm = TRUE ) svyby( ~ bmipct , ~ ever_smoked_marijuana , yrbss_design , svytotal , na.rm = TRUE ) Calculate the weighted sum of a categorical variable, overall and by groups: svytotal( ~ q2 , yrbss_design , na.rm = TRUE ) svyby( ~ q2 , ~ ever_smoked_marijuana , yrbss_design , svytotal , na.rm = TRUE ) Calculate the median (50th percentile) of a linear variable, overall and by groups: svyquantile( ~ bmipct , yrbss_design , 0.5 , na.rm = TRUE ) svyby( ~ bmipct , ~ ever_smoked_marijuana , yrbss_design , svyquantile , 0.5 , ci = TRUE , keep.var = TRUE , na.rm = TRUE ) Estimate a ratio: svyratio( numerator = ~ ever_tried_to_quit_cigarettes , denominator = ~ smoked_cigarettes_past_year , yrbss_design , na.rm = TRUE ) Subsetting Restrict the survey design to youths who ever drank alcohol: sub_yrbss_design &lt;- subset( yrbss_design , qn41 == 1 ) Calculate the mean (average) of this subset: svymean( ~ bmipct , sub_yrbss_design , na.rm = TRUE ) Measures of Uncertainty Extract the coefficient, standard error, confidence interval, and coefficient of variation from any descriptive statistics function result, overall and by groups: this_result &lt;- svymean( ~ bmipct , yrbss_design , na.rm = TRUE ) coef( this_result ) SE( this_result ) confint( this_result ) cv( this_result ) grouped_result &lt;- svyby( ~ bmipct , ~ ever_smoked_marijuana , yrbss_design , svymean , na.rm = TRUE ) coef( grouped_result ) SE( grouped_result ) confint( grouped_result ) cv( grouped_result ) Calculate the degrees of freedom of any survey design object: degf( yrbss_design ) Calculate the complex sample survey-adjusted variance of any statistic: svyvar( ~ bmipct , yrbss_design , na.rm = TRUE ) Include the complex sample design effect in the result for a specific statistic: # SRS without replacement svymean( ~ bmipct , yrbss_design , na.rm = TRUE , deff = TRUE ) # SRS with replacement svymean( ~ bmipct , yrbss_design , na.rm = TRUE , deff = &quot;replace&quot; ) Compute confidence intervals for proportions using methods that may be more accurate near 0 and 1. See ?svyciprop for alternatives: svyciprop( ~ never_rarely_wore_bike_helmet , yrbss_design , method = &quot;likelihood&quot; , na.rm = TRUE ) Regression Models and Tests of Association Perform a design-based t-test: svyttest( bmipct ~ never_rarely_wore_bike_helmet , yrbss_design ) Perform a chi-squared test of association for survey data: svychisq( ~ never_rarely_wore_bike_helmet + q2 , yrbss_design ) Perform a survey-weighted generalized linear model: glm_result &lt;- svyglm( bmipct ~ never_rarely_wore_bike_helmet + q2 , yrbss_design ) summary( glm_result ) Analysis Examples with srvyr   The R srvyr library calculates summary statistics from survey data, such as the mean, total or quantile using dplyr-like syntax. srvyr allows for the use of many verbs, such as summarize, group_by, and mutate, the convenience of pipe-able functions, the tidyverse style of non-standard evaluation and more consistent return types than the survey package. This vignette details the available features. As a starting point for YRBSS users, this code replicates previously-presented examples: library(srvyr) yrbss_srvyr_design &lt;- as_survey( yrbss_design ) Calculate the mean (average) of a linear variable, overall and by groups: yrbss_srvyr_design %&gt;% summarize( mean = survey_mean( bmipct , na.rm = TRUE ) ) yrbss_srvyr_design %&gt;% group_by( ever_smoked_marijuana ) %&gt;% summarize( mean = survey_mean( bmipct , na.rm = TRUE ) ) Replication Example This snippet replicates the “never/rarely wore bicycle helmet” row of PDF page 29 of this CDC analysis software document. unwtd.count( ~ never_rarely_wore_bike_helmet , yrbss_design ) svytotal( ~ one , subset( yrbss_design , !is.na( never_rarely_wore_bike_helmet ) ) ) svymean( ~ never_rarely_wore_bike_helmet , yrbss_design , na.rm = TRUE ) svyciprop( ~ never_rarely_wore_bike_helmet , yrbss_design , na.rm = TRUE , method = &quot;beta&quot; ) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
