# National Longitudinal Surveys (NLS) {-}

[![Build Status](https://travis-ci.org/asdfree/nls.svg?branch=master)](https://travis-ci.org/asdfree/nls) [![Build status](https://ci.appveyor.com/api/projects/status/github/asdfree/nls?svg=TRUE)](https://ci.appveyor.com/project/ajdamico/nls)

The National Longitudinal Surveys follow the same sample of individuals from specific birth cohorts over time. The surveys collect data on labor market activity, schooling, fertility, program participation, and health.

* Multiple panels, each with one table with one row per sampled panel respondent.

* A series of complex sample surveys designed to generalize to various cohorts of Americans born during [designated time periods](https://www.bls.gov/nls/overview.htm).

* Updated biennally for most active panels.

* Administered by the [Bureau of Labor Statistics](http://www.bls.gov/).

## Simplified Download and Importation {-}

The R `lodown` package easily downloads and imports all available NLS microdata by simply specifying `"nls"` with an `output_dir =` parameter in the `lodown()` function. Depending on your internet connection and computer processing speed, you might prefer to run this step overnight.

```{r eval = FALSE }
library(lodown)
lodown( "nls" , output_dir = file.path( path.expand( "~" ) , "NLS" ) )
```

`lodown` also provides a catalog of available microdata extracts with the `get_catalog()` function. After requesting the NLS catalog, you could pass a subsetted catalog through the `lodown()` function in order to download and import specific extracts (rather than all available extracts).

```{r eval = FALSE , results = "hide" }
library(lodown)
# examine all available NLS microdata files
nls_cat <-
	get_catalog( "nls" ,
		output_dir = file.path( path.expand( "~" ) , "NLS" ) )

# National Longitudinal Survey of Youth, 1997 only
nls_cat <- subset( nls_cat , study_name == 'NLS Youth 1997 (NLSY97)' )
# download the microdata to your local computer
nls_cat <- lodown( "nls" , nls_cat )
```

## Analysis Examples with the `survey` library \ {-}

Construct a complex sample survey design:

```{r eval = FALSE }

```

```{r eval = FALSE }
options( survey.lonely.psu = "adjust" )

library(survey)

nlsy_files <- 
	list.files(
		file.path( path.expand( "~" ) , "NLS" ) ,
		full.names = TRUE ,
		recursive = TRUE
	)

# read in the R loading script
nlsy97_r <- 
	readLines( nlsy_files[ grepl( "nlsy97(.*)R$" , basename( nlsy_files ) ) ] )

# find all instances of "data$" in the r script
data_dollar <- grep( "data\\$" , nlsy97_r )
	
# extract the column names from the R script
first_line <- grep( "names(new_data) <-" , nlsy97_r , fixed = TRUE )
close_parentheses <- grep( ")" , nlsy97_r , fixed = TRUE )
last_line <- min( close_parentheses[ close_parentheses > first_line ] )
column_names_lines <- nlsy97_r[ seq( first_line , last_line ) ]
column_names_lines <- 
	gsub( 'names(new_data) <-' , 'column_names <-' , column_names_lines , fixed = TRUE )
eval( parse( text = column_names_lines ) )

# choose which columns to import
columns_to_import <-
	c( 'R0000100' , 'T5206900' , 'R9829600' , 'R0536300' , 'Z9061800' , 'T6657200' , 'R1205300' )

	
# for each column to import, look for a recoding block
find_recoding_block <-
	function( w ){
		
		this_block_start <- min( grep( paste0( "data\\$" , w ) , nlsy97_r ) )
		
		recode_lines <- 
			seq( 
				this_block_start , 
				min( data_dollar[ data_dollar > this_block_start ] ) - 1 
			)
			
		paste( nlsy97_r[ recode_lines ] , collapse = '' )
		
	}

recodes_to_run <- unlist( lapply( columns_to_import , find_recoding_block ) )
	
# readr::read_delim() columns must match their order in the csv file
columns_to_import <-
	columns_to_import[ order( match( columns_to_import , column_names ) ) ]

	
# confirm all column names are available
stopifnot( all( columns_to_import %in% column_names ) )

# identify the .dat file
nlsy97_dat <- nlsy_files[ grepl( "nlsy97(.*)dat$" , basename( nlsy_files ) ) ]

nls_variables_df <- 
	data.frame( 
		readr::read_delim( 
			nlsy97_dat , 
			col_names = columns_to_import , 
			col_types = 
				paste0( 
					ifelse( column_names %in% columns_to_import , 'n' , '_' ) , 
					collapse = "" 
				) ,
			delim = ' '
		) 
	)

# remove all missings
nls_variables_df[ nls_variables_df < 0 ] <- NA

recodes_to_run <- 
	gsub( "data\\$" , "nls_variables_df$" , recodes_to_run )

# align the main variables with what the R script says	
for( this_recode in recodes_to_run ) eval( parse( text = this_recode ) )

# cluster and strata variables
nls_psustr_df <-
	readRDS( grep( "strpsu\\.rds$" , nlsy_files , value = TRUE ) )
	
# you can read more about longitudinal weights here
# http://www.nlsinfo.org/weights

# the lodown:::get_nlsy_weights function returns a data.frame object
# containing the unique person identifiers and also a column of weights.

# view which points-in-time are available for a particular study
# lodown:::get_nlsy_selections( "nlsy97" )

# download weights for respondents in 1997
w <- lodown:::nls_get_weights( "nlsy97" , 'YES' , 'SURV1997' )

# download weights for respondents who were in any of the 1997, 2002, or 2007 surveys
# w <- 
# 	lodown:::nls_get_weights( "nlsy97" , 'YES' , c( 'SURV1997' , 'SURV2002' , 'SURV2007' ) )

# download weights for respondents who were in all of the 1997, 2002, and 2007 surveys
# w <- 
# 	lodown:::nls_get_weights( "nlsy97" , 'NO' , c( 'SURV1997' , 'SURV2002' , 'SURV2007' ) )

# download weights for respondents who are in all available surveys
# w <- 
# 	lodown:::nls_get_weights( "nlsy97" , "NO" , lodown:::nls_get_selections( "nlsy97" ) )

# merge weights with cluster and strata variables
nls_survey_df <- merge( nls_psustr_df , w )

# merge variables onto survey design
nls_df <- merge( nls_variables_df , nls_survey_df )

nls_design <- 
	svydesign( 
		~ R1489800 , 
		strata = ~ R1489700 , 
		data = x ,
		weights = ~ weight ,
		nest = TRUE
	)
```

### Variable Recoding {-}

Add new columns to the data set:
```{r eval = FALSE }
nls_design <- 
	update( 
		nls_design , 
		bachelors_degree_or_higher = as.numeric( T6657200 >= 5 )
	)
```

### Unweighted Counts {-}

Count the unweighted number of records in the survey sample, overall and by groups:
```{r eval = FALSE , results = "hide" }
sum( weights( nls_design , "sampling" ) != 0 )

svyby( ~ one , ~ R1205300 , nls_design , unwtd.count )
```

### Weighted Counts {-}
Count the weighted size of the generalizable population, overall and by groups:
```{r eval = FALSE , results = "hide" }
svytotal( ~ one , nls_design )

svyby( ~ one , ~ R1205300 , nls_design , svytotal )
```

### Descriptive Statistics {-}

Calculate the mean (average) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svymean( ~ T7545600 , nls_design , na.rm = TRUE )

svyby( ~ T7545600 , ~ R1205300 , nls_design , svymean , na.rm = TRUE )
```

Calculate the distribution of a categorical variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svymean( ~ T6657200 , nls_design , na.rm = TRUE )

svyby( ~ T6657200 , ~ R1205300 , nls_design , svymean , na.rm = TRUE )
```

Calculate the sum of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svytotal( ~ T7545600 , nls_design , na.rm = TRUE )

svyby( ~ T7545600 , ~ R1205300 , nls_design , svytotal , na.rm = TRUE )
```

Calculate the weighted sum of a categorical variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svytotal( ~ T6657200 , nls_design , na.rm = TRUE )

svyby( ~ T6657200 , ~ R1205300 , nls_design , svytotal , na.rm = TRUE )
```

Calculate the median (50th percentile) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svyquantile( ~ T7545600 , nls_design , 0.5 , na.rm = TRUE )

svyby( 
	~ T7545600 , 
	~ R1205300 , 
	nls_design , 
	svyquantile , 
	0.5 ,
	ci = TRUE ,
	keep.var = TRUE ,
	na.rm = TRUE
)
```

Estimate a ratio:
```{r eval = FALSE , results = "hide" }
svyratio( 
	numerator = ~ R9829600 , 
	denominator = ~ T7545600 , 
	nls_design ,
	na.rm = TRUE
)
```

### Subsetting {-}

Restrict the survey design to raised by only biological mother or father in 1997:
```{r eval = FALSE , results = "hide" }
sub_nls_design <- subset( nls_design , R1205300 %in% 4:5 )
```
Calculate the mean (average) of this subset:
```{r eval = FALSE , results = "hide" }
svymean( ~ T7545600 , sub_nls_design , na.rm = TRUE )
```

### Measures of Uncertainty {-}

Extract the coefficient, standard error, confidence interval, and coefficient of variation from any descriptive statistics function result, overall and by groups:
```{r eval = FALSE , results = "hide" }
this_result <- svymean( ~ T7545600 , nls_design , na.rm = TRUE )

coef( this_result )
SE( this_result )
confint( this_result )
cv( this_result )

grouped_result <-
	svyby( 
		~ T7545600 , 
		~ R1205300 , 
		nls_design , 
		svymean ,
		na.rm = TRUE 
	)
	
coef( grouped_result )
SE( grouped_result )
confint( grouped_result )
cv( grouped_result )
```

Calculate the degrees of freedom of any survey design object:
```{r eval = FALSE , results = "hide" }
degf( nls_design )
```

Calculate the complex sample survey-adjusted variance of any statistic:
```{r eval = FALSE , results = "hide" }
svyvar( ~ T7545600 , nls_design , na.rm = TRUE )
```

Include the complex sample design effect in the result for a specific statistic:
```{r eval = FALSE , results = "hide" }
# SRS without replacement
svymean( ~ T7545600 , nls_design , na.rm = TRUE , deff = TRUE )

# SRS with replacement
svymean( ~ T7545600 , nls_design , na.rm = TRUE , deff = "replace" )
```

Compute confidence intervals for proportions using methods that may be more accurate near 0 and 1. See `?svyciprop` for alternatives:
```{r eval = FALSE , results = "hide" }
svyciprop( ~ bachelors_degree_or_higher , nls_design ,
	method = "likelihood" , na.rm = TRUE )
```

### Regression Models and Tests of Association {-}

Perform a design-based t-test:
```{r eval = FALSE , results = "hide" }
svyttest( T7545600 ~ bachelors_degree_or_higher , nls_design )
```

Perform a chi-squared test of association for survey data:
```{r eval = FALSE , results = "hide" }
svychisq( 
	~ bachelors_degree_or_higher + T6657200 , 
	nls_design 
)
```

Perform a survey-weighted generalized linear model:
```{r eval = FALSE , results = "hide" }
glm_result <- 
	svyglm( 
		T7545600 ~ bachelors_degree_or_higher + T6657200 , 
		nls_design 
	)

summary( glm_result )
```

## Analysis Examples with `srvyr` \ {-}

The R `srvyr` library calculates summary statistics from survey data, such as the mean, total or quantile using [dplyr](https://github.com/tidyverse/dplyr/)-like syntax. [srvyr](https://github.com/gergness/srvyr) allows for the use of many verbs, such as `summarize`, `group_by`, and `mutate`, the convenience of pipe-able functions, the `tidyverse` style of non-standard evaluation and more consistent return types than the `survey` package. [This vignette](https://cran.r-project.org/web/packages/srvyr/vignettes/srvyr-vs-survey.html) details the available features. As a starting point for NLS users, this code replicates previously-presented examples:

```{r eval = FALSE , results = "hide" }
library(srvyr)
nls_srvyr_design <- as_survey( nls_design )
```
Calculate the mean (average) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
nls_srvyr_design %>%
	summarize( mean = survey_mean( T7545600 , na.rm = TRUE ) )

nls_srvyr_design %>%
	group_by( R1205300 ) %>%
	summarize( mean = survey_mean( T7545600 , na.rm = TRUE ) )
```


