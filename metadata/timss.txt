
chapter_title: Trends in International Mathematics and Science Study

needs_actions_build_status_line: yes



~~~{replacement_block}
MIcombine
timss_MIcombine
~~~





~~~{dataset_introduction}
The Trends in International Mathematics and Science Study (TIMSS) tracks the math and science competency of fourth graders across about fifty nations.
~~~

table_structure: * A series of tables with one record per school (ACG), per student (ASG), per teacher (ATG), as well as files containing student achievement (ASA), home background (ASH), student-teacher linkage (AST), and within-country scoring reliability (ASR).

generalizable_population: * A complex sample survey designed to generalize to the fourth-grade student population of participating countries.

publication_period: * Released quadrennially since 1995.

administrative_organization: * Funded by the [International Association for the Evaluation of Educational Achievement](https://www.iea.nl/) and compiled by the [Lynch School of Education at Boston College](http://www.bc.edu/bc-web/schools/lsoe.html).




~~~{reading_block}
Please skim before you begin:

1. [TIMSS 2019 User Guide for the International Database, 2nd Edition](https://timss2019.org/international-database/downloads/TIMSS-2019-User-Guide-for-the-International-Database-2nd-Ed.pdf)

2. [Methods and Procedures: TIMSS 2019 Technical Report](https://timssandpirls.bc.edu/timss2019/methods/pdf/TIMSS-2019-MP-Technical-Report.pdf)

3. This human-composed haiku or a bouquet of [artificial intelligence-generated limericks](https://www.gnod.com/search/ai#q=write%20a%20limerick-style%20poem%20about%20the%20chapter_title)

```{r}
# brando for stella,
# gump's jenny, rock's adrian,
# students toward math test
```
~~~



~~~{definitions_block}
## Function Definitions {-}

This survey uses a multiply-imputed variance estimation technique described in the [2004 Codebook](https://www.federalreserve.gov/econres/files/2004_codebk2004.txt).  Most users do not need to study this function carefully.  Define a function specific to only this dataset:

```{r eval = FALSE , results = "hide" }
MIcombine <-
	function (results, variances, call = sys.call(), df.complete = Inf, ...) {
		m <- length(results)
		oldcall <- attr(results, "call")
		if (missing(variances)) {
			variances <- suppressWarnings(lapply(results, vcov))
			results <- lapply(results, coef)
		}
		vbar <- variances[[1]]
		cbar <- results[[1]]
		for (i in 2:m) {
			cbar <- cbar + results[[i]]
			vbar <- vbar + variances[[i]]
		}
		cbar <- cbar/m
		vbar <- vbar/m

		# MODIFICATION
		# evar <- var(do.call("rbind", results))
		evar <- sum( ( unlist( results ) - cbar )^2 / 4 )

		
		r <- (1 + 1/m) * evar/vbar
		df <- (m - 1) * (1 + 1/r)^2
		if (is.matrix(df)) df <- diag(df)
		if (is.finite(df.complete)) {
			dfobs <- ((df.complete + 1)/(df.complete + 3)) * df.complete *
			vbar/(vbar + evar)
			if (is.matrix(dfobs)) dfobs <- diag(dfobs)
			df <- 1/(1/dfobs + 1/df)
		}
		if (is.matrix(r)) r <- diag(r)
		rval <- list(coefficients = cbar, variance = vbar + evar *
		(m + 1)/m, call = c(oldcall, call), nimp = m, df = df,
		missinfo = (r + 2/(df + 3))/(r + 1))
		class(rval) <- "MIresult"
		rval
	}
```
---
~~~



~~~{download_and_import_block}

Download and unzip the 2019 fourth grade international database:

```{r message = FALSE , eval = FALSE }
library(httr)

tf <- tempfile()

this_url <- "https://timss2019.org/international-database/downloads/T19_G4_SPSS%20Data.zip"

GET( this_url , write_disk( tf ) , progress() )

unzipped_files <- unzip( tf , exdir = tempdir() )
```

Import and stack each of the student context data files for all countries and benchmarking participants:

```{r message = FALSE , eval = FALSE }
library(haven)

chapter_tag_df <- NULL

for( spss_fn in unzipped_files[ grepl( '^asg[a-z][a-z][a-z]m7' , basename( unzipped_files ) ) ] ){

	this_tbl <- read_spss( spss_fn )
	
	this_tbl <- zap_labels( this_tbl )
	
	this_df <- data.frame( this_tbl )
	
	names( this_df ) <- tolower( names( this_df ) )
	
	chapter_tag_df <- rbind( chapter_tag_df , this_df )
	
}

chapter_tag_df <- chapter_tag_df[ with( chapter_tag_df , order( idcntry , idstud ) ) , ]
```
~~~





~~~{analysis_examples_survey_design}


```{r message = FALSE , eval = FALSE }
ppv <- grep( "(.*)0[1-5]$" , names( chapter_tag_df ) , value = TRUE )
ppv_prefix <- gsub( "0[1-5]$" , "" , ppv )
pv <- names( table( ppv_prefix )[ table( ppv_prefix ) == 5 ] )
pv_columns <- grep( paste0( "^" , pv , "0[1-5]$" , collapse = "|" ) , names( chapter_tag_df ) , value = TRUE )

id_columns <- c( 'idcntry' , 'idstud' )

pv_wide_df <- chapter_tag_df[ c( id_columns , pv_columns ) ]

chapter_tag_df[ pv_columns ] <- NULL




pv_long_df <- 
	reshape( 
		pv_wide_df , 
		varying = lapply( paste0( pv , '0' ) , paste0 , 1:5 ) , 
		direction = 'long' , 
		timevar = 'implicate' , 
		idvar = id_columns 
	)


names( pv_long_df ) <- gsub( "01$" , "" , names( pv_long_df ) )

chapter_tag_long_df <- merge( chapter_tag_df , pv_long_df )

chapter_tag_long_df <- chapter_tag_long_df[ with( chapter_tag_long_df , order( idcntry , idstud ) ) , ]

stopifnot( nrow( chapter_tag_long_df ) == nrow( pv_long_df ) )

stopifnot( nrow( chapter_tag_long_df ) / 5 == nrow( chapter_tag_df ) )
```


Reshape the plausible values data.frame into a list based on the implicate number:
```{r message = FALSE , eval = FALSE }
chapter_tag_list <- split( chapter_tag_long_df , chapter_tag_long_df[ , 'implicate' ] )
```


```{r message = FALSE , eval = FALSE }
weights_df <- chapter_tag_df[ c( 'jkrep' , 'jkzone' ) ]

for( j in 1:75 ){
	for( i in 0:1 ){
		weights_df[ weights_df[ , 'jkzone' ] != j , paste0( 'rw' , i , j ) ] <- 1
		
		weights_df[ weights_df[ , 'jkzone' ] == j , paste0( 'rw' , i , j ) ] <- 
			2 * ( weights_df[ weights_df[ , 'jkzone' ] == j , 'jkrep' ] == i )
	}
}

weights_df[ c( 'jkrep' , 'jkzone' ) ] <- NULL

```


Define the design:
```{r message = FALSE , eval = FALSE }
library(survey)
library(mitools)

chapter_tag_design <- 
	svrepdesign(
		weights = ~totwgt ,
		repweights = weights_df , 
		data = imputationList( chapter_tag_list ) ,
		type = "other" ,
		scale = 0.5 ,
		rscales = rep( 1 , 150 ) ,
		combined.weights = FALSE ,
		mse = TRUE
	)
```
~~~



~~~{variable_recoding_block}
chapter_tag_design <- 
	update( 
		chapter_tag_design , 
		
		one = 1 ,
		
		idcntry = factor( idcntry ) ,
		
		sex = factor( itsex , labels = c( "male" , "female" ) ) ,
		
		born_2005_or_later = as.numeric( itbirthy >= 2005 )

	)
~~~

group_by_variable: sex
linear_variable: asmmat
categorical_variable: idcntry
ratio_estimation_numerator: asssci
ratio_estimation_denominator: asmmat
subset_definition: idcntry %in% c( 36 , 40 , 31 , 957 )
subset_definition_description: Australia, Austria, Azerbaijan, Belgium (French)
binary_variable: born_2001_or_later
binary_narm: , na.rm = TRUE

~~~{replication_example_block}
## Replication Example {-}

```{r eval = FALSE , results = "hide" }
chapter_tag_design <- update( chapter_tag_design , one = 1 )
w <- subset( chapter_tag_design , idcntry == 36 )
nrow(w)
lapply( w$designs , function( u ) vcov( svymean( ~ asmmat , u ) ) )
mean( unlist( lapply( w$designs , function( u ) vcov( svymean( ~ asmmat , u ) ) ) ) )
MIcombine( with( w , svymean( ~ asmmat ) ) )





library(haven)

this_df <- read_spss( grep( 'asgaus' , unzipped_files , value = TRUE ) )
this_df <- zap_labels( this_df )
this_df <- data.frame( this_df )
names( this_df ) <- tolower( names( this_df ) )

mean( c(
	with( this_df , weighted.mean( asmmat01 , totwgt ) ) ,
	with( this_df , weighted.mean( asmmat02 , totwgt ) ) ,
	with( this_df , weighted.mean( asmmat03 , totwgt ) ) ,
	with( this_df , weighted.mean( asmmat04 , totwgt ) ) ,
	with( this_df , weighted.mean( asmmat05 , totwgt ) )
) )



for( k in 1:5 ){

	this_variance <- 0
	
	for( j in 1:75 ){
		for( i in 0:1 ){
			this_variance <- 
				this_variance + 
				( 
					weighted.mean( 
						this_df[ , paste0( 'asmmat0' , k ) ] , 
						ifelse( j == this_df[ , 'jkzone' ] , this_df[ , 'totwgt' ] * 2 * ( this_df[ , 'jkrep' ] == i ) , this_df[ , 'totwgt' ] )
					) -
					weighted.mean( 
						this_df[ , paste0( 'asmmat0' , k ) ] , 
						this_df[ , 'totwgt' ]
					)
				)^2
		}
	}
	
	assign( paste0( 'v' , k ) , this_variance * 0.5 )

}

# sampling variance
mean( c( v1 , v2 , v3 , v4 , v5 ) )



t0 <-
	mean( c(
		with( this_df , weighted.mean( asmmat01 , totwgt ) ) ,
		with( this_df , weighted.mean( asmmat02 , totwgt ) ) ,
		with( this_df , weighted.mean( asmmat03 , totwgt ) ) ,
		with( this_df , weighted.mean( asmmat04 , totwgt ) ) ,
		with( this_df , weighted.mean( asmmat05 , totwgt ) )
	) )


# imputation variance
( 6 / 5 ) * 
	( 
		( ( with( this_df , weighted.mean( asmmat01 , totwgt ) ) - t0 )^2 / 4 ) +
		( ( with( this_df , weighted.mean( asmmat02 , totwgt ) ) - t0 )^2 / 4 ) +
		( ( with( this_df , weighted.mean( asmmat03 , totwgt ) ) - t0 )^2 / 4 ) +
		( ( with( this_df , weighted.mean( asmmat04 , totwgt ) ) - t0 )^2 / 4 ) +
		( ( with( this_df , weighted.mean( asmmat05 , totwgt ) ) - t0 )^2 / 4 ) 
	)

```
~~~


