chapter_title: American Community Survey

needs_actions_build_status_line: yes

~~~{dataset_introduction}
The US Census Bureau's annual replacement for the long-form decennial census.
~~~

table_structure: * Two tables per state, the first with one row per household and the second with one row per individual.

generalizable_population: * The civilian population of the United States.

publication_period: * Released annually since 2005.

administrative_organization: * Administered and financed by the [US Census Bureau](http://www.census.gov/).

~~~{reading_block}
Please skim before you begin:

1. [Guidance for Data Users](https://www.census.gov/programs-surveys/acs/guidance.html)

2. [Wikipedia Entry](https://en.wikipedia.org/wiki/American_Community_Survey)

3. A haiku regarding this microdata:

```{r}
# one percent sample
# the decennial census
# in miniature
```
~~~


~~~{download_and_import_block}

Choose either the entire **United States** with `sas_hus.zip`, or use a state's abbreviation like `sas_hal.zip` for **Alabama** or `sas_hak.zip` for **Alaska**.  This imports the **Alabama** household file:

```{r eval = FALSE , results = "hide" }
library(haven)

tf_household <- tempfile()

this_url_household <-
	"https://www2.census.gov/programs-surveys/acs/data/pums/2022/1-Year/sas_hal.zip"

download.file( this_url_household , tf_household , mode = 'wb' )

unzipped_files_household <- unzip( tf_household , exdir = tempdir() )

chapter_tag_sas_household <-
	grep( '\\\\.sas7bdat$' , unzipped_files_household , value = TRUE )

chapter_tag_df_household <- read_sas( chapter_tag_sas_household )

names( chapter_tag_df_household ) <- tolower( names( chapter_tag_df_household ) )
```


Choose either the entire **United States** with `sas_pus.zip`, or use a state's abbreviation like `sas_pal.zip` for **Alabama** or `sas_pak.zip` for **Alaska**.  This imports the **Alabama** person file:


```{r eval = FALSE , results = "hide" }
tf_person <- tempfile()

this_url_person <-
	"https://www2.census.gov/programs-surveys/acs/data/pums/2022/1-Year/sas_pal.zip"

download.file( this_url_person , tf_person , mode = 'wb' )

unzipped_files_person <- unzip( tf_person , exdir = tempdir() )

chapter_tag_sas_person <-
	grep( '\\\\.sas7bdat$' , unzipped_files_person , value = TRUE )

chapter_tag_df_person <- read_sas( chapter_tag_sas_person )

names( chapter_tag_df_person ) <- tolower( names( chapter_tag_df_person ) )
```


Remove overlapping column and merge household + person files:
```{r eval = FALSE , results = "hide" }

chapter_tag_df_household[ , 'rt' ] <- NULL

chapter_tag_df_person[ , 'rt' ] <- NULL

chapter_tag_df <- merge( chapter_tag_df_household , chapter_tag_df_person )
	
stopifnot( nrow( chapter_tag_df ) == nrow( chapter_tag_df_person ) )

chapter_tag_df[ , 'one' ] <- 1
```
~~~



~~~{analysis_examples_survey_design}
```{r eval = FALSE , results = "hide" }
library(survey)

chapter_tag_design <-
	svrepdesign(
		weight = ~pwgtp ,
		repweights = 'pwgtp[0-9]+' ,
		scale = 4 / 80 ,
		rscales = rep( 1 , 80 ) ,
		mse = TRUE ,
		type = 'JK1' ,
		data = chapter_tag_df
	)
```
~~~


~~~{variable_recoding_block}
chapter_tag_design <-
	update(
		
		chapter_tag_design ,
		
		state_name =
			factor(
				as.numeric( st ) ,
				levels = 
					c(1L, 2L, 4L, 5L, 6L, 8L, 9L, 10L, 
					11L, 12L, 13L, 15L, 16L, 17L, 18L, 
					19L, 20L, 21L, 22L, 23L, 24L, 25L, 
					26L, 27L, 28L, 29L, 30L, 31L, 32L, 
					33L, 34L, 35L, 36L, 37L, 38L, 39L, 
					40L, 41L, 42L, 44L, 45L, 46L, 47L, 
					48L, 49L, 50L, 51L, 53L, 54L, 55L, 
					56L, 72L) ,
				labels =
					c("Alabama", "Alaska", "Arizona", "Arkansas", "California", 
					"Colorado", "Connecticut", "Delaware", "District of Columbia", 
					"Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", 
					"Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", 
					"Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", 
					"Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", 
					"New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", 
					"Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", 
					"South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", 
					"Washington", "West Virginia", "Wisconsin", "Wyoming", "Puerto Rico")
			) ,
		
		cit =
			factor( 
				cit , 
				levels = 1:5 , 
				labels = 
					c( 
						'born in the u.s.' ,
						'born in the territories' ,
						'born abroad to american parents' ,
						'naturalized citizen' ,
						'non-citizen'
					)
			) ,
		
		poverty_level = as.numeric( povpip ) ,
		
		married = as.numeric( mar %in% 1 ) ,
		
		sex = factor( sex , labels = c( 'male' , 'female' ) )
	)
~~~


group_by_variable: cit
linear_variable: poverty_level
linear_narm: , na.rm = TRUE
categorical_variable: sex
ratio_estimation_numerator: ssip
ratio_estimation_denominator: pincp
ratio_narm: , na.rm = TRUE
subset_definition: agep >= 65
subset_definition_description: senior citizens
binary_variable: married


needs_srvyr_block: yes



~~~{convey_block}
## Poverty and Inequality Estimation with `convey` \\ {-}

The R `convey` library estimates measures of income concentration, poverty, inequality, and wellbeing.  [This textbook](https://guilhermejacob.github.io/context/) details the available features.  As a starting point for CHAPTER_TAG users, this code calculates the gini coefficient on complex sample survey data:

```{r eval = FALSE , results = "hide" }
library(convey)
chapter_tag_design <- convey_prep( chapter_tag_design )

svygini( ~ hincp , chapter_tag_design , na.rm = TRUE )
```
~~~



~~~{replication_example_block}
## Replication Example {-}

This matches statistics, standard errors, and margin of errors from Alabama's [2022 PUMS tallies](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/estimates/pums_estimates_22.csv):

Match the sum of the weights:

```{r eval = FALSE , results = "hide" }
stopifnot( round( coef( svytotal( ~ one , chapter_tag_design ) ) , 0 ) == 5074296 )
```
	
	
Compute the population by age:

```{r eval = FALSE , results = "hide" }
pums_estimate <- 
	c(277094L, 316627L, 319132L, 336759L, 350132L, 651975L, 633907L, 
	616899L, 317765L, 341937L, 543576L, 284790L, 83703L)

pums_standard_error <- 
	c(2624L, 5197L, 5002L, 4112L, 3626L, 5047L, 4559L, 4538L, 5849L, 
	5731L, 2061L, 3527L, 2896L)

pums_margin_of_error <- 
	c(4317L, 8550L, 8229L, 6764L, 5964L, 8302L, 7499L, 7465L, 9622L, 
	9427L, 3390L, 5801L, 4765L)


results <-
	svytotal( 
		~ as.numeric( agep %in% 0:4 ) +
		as.numeric( agep %in% 5:9 ) +
		as.numeric( agep %in% 10:14 ) +
		as.numeric( agep %in% 15:19 ) +
		as.numeric( agep %in% 20:24 ) +
		as.numeric( agep %in% 25:34 ) +
		as.numeric( agep %in% 35:44 ) +
		as.numeric( agep %in% 45:54 ) +
		as.numeric( agep %in% 55:59 ) +
		as.numeric( agep %in% 60:64 ) +
		as.numeric( agep %in% 65:74 ) +
		as.numeric( agep %in% 75:84 ) +
		as.numeric( agep %in% 85:100 ) , 
		chapter_tag_design
	)

stopifnot( all( round( coef( results ) , 0 ) == pums_estimate ) )

stopifnot( all( round( SE( results ) , 0 ) == pums_standard_error ) )

stopifnot( all( round( SE( results ) * 1.645 , 0 ) == pums_margin_of_error ) )

```

~~~











