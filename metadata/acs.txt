chapter_title: American Community Survey

needs_actions_build_status_line: yes

~~~{dataset_introduction}
The US Census Bureau's annual replacement for the long-form decennial census.
~~~

table_structure: * Two tables per state, the first with one row per household and the second with one row per individual within each household.

generalizable_population: * The civilian population of the United States.

publication_period: * Released annually since 2005.

administrative_organization: * Administered and financed by the [US Census Bureau](http://www.census.gov/).

~~~{reading_block}
Please skim before you begin:

1. [Guidance for Data Users](https://www.census.gov/programs-surveys/acs/guidance.html)

2. [Wikipedia Entry](https://en.wikipedia.org/wiki/American_Community_Survey)

3. This poem

```{r}
# one percent sample
# the decennial census
# in miniature
```
~~~


~~~{download_and_import_block}

Load the `haven` library to import sas files:
```{r eval = FALSE }
library(haven)
```


Download and import the Alabama household file:

(switch `sas_hal` to `sas_hak` for Alaska or `sas_hus` for the entire country)
```{r eval = FALSE }
tf_household <- tempfile()

this_url_household <-
	"https://www2.census.gov/programs-surveys/acs/data/pums/2021/1-Year/sas_hal.zip"

download.file( this_url_household , tf_household , mode = 'wb' )

unzipped_files_household <- unzip( tf_household , exdir = tempdir() )

chapter_tag_sas_household <-
	grep( '\\\\.sas7bdat$' , unzipped_files_household , value = TRUE )

chapter_tag_df_household <- haven::read_sas( chapter_tag_sas_household )

names( chapter_tag_df_household ) <- tolower( names( chapter_tag_df_household ) )
```

Download and import the Alabama person file:

(switch `sas_pal` to `sas_pak` for Alaska or `sas_pus` for the entire country)
```{r eval = FALSE }
tf_person <- tempfile()

this_url_person <-
	"https://www2.census.gov/programs-surveys/acs/data/pums/2021/1-Year/sas_pal.zip"

download.file( this_url_person , tf_person , mode = 'wb' )

unzipped_files_person <- unzip( tf_person , exdir = tempdir() )

chapter_tag_sas_person <-
	grep( '\\\\.sas7bdat$' , unzipped_files_person , value = TRUE )

chapter_tag_df_person <- haven::read_sas( chapter_tag_sas_person )

names( chapter_tag_df_person ) <- tolower( names( chapter_tag_df_person ) )
```


Remove overlapping column and merge household + person files:
```{r eval = FALSE }

chapter_tag_df_household[ , 'rt' ] <- NULL

chapter_tag_df_person[ , 'rt' ] <- NULL

chapter_tag_df <- merge( chapter_tag_df_household , chapter_tag_df_person )
	
stopifnot( nrow( chapter_tag_df ) == nrow( chapter_tag_df_person ) )

chapter_tag_df[ , 'one' ] <- 1
```
~~~



~~~{analysis_examples_survey_design}
library(survey)

chapter_tag_design <-
	svrepdesign(
		weight = ~pwgtp ,
		repweights = 'pwgtp[0-9]+' ,
		scale = 4 / 80 ,
		rscales = rep( 1 , 80 ) ,
		mse = TRUE ,
		type = 'JK1' ,
		data = chapter_tag_df
	)
~~~


~~~{variable_recoding_block}
chapter_tag_design <-
	update(
		
		chapter_tag_design ,
		
		state_name =
			factor(
				as.numeric( st ) ,
				levels = 
					c(1L, 2L, 4L, 5L, 6L, 8L, 9L, 10L, 
					11L, 12L, 13L, 15L, 16L, 17L, 18L, 
					19L, 20L, 21L, 22L, 23L, 24L, 25L, 
					26L, 27L, 28L, 29L, 30L, 31L, 32L, 
					33L, 34L, 35L, 36L, 37L, 38L, 39L, 
					40L, 41L, 42L, 44L, 45L, 46L, 47L, 
					48L, 49L, 50L, 51L, 53L, 54L, 55L, 
					56L, 72L) ,
				labels =
					c("Alabama", "Alaska", "Arizona", "Arkansas", "California", 
					"Colorado", "Connecticut", "Delaware", "District of Columbia", 
					"Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", 
					"Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", 
					"Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", 
					"Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", 
					"New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", 
					"Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", 
					"South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", 
					"Washington", "West Virginia", "Wisconsin", "Wyoming", "Puerto Rico")
			) ,
		
		cit =
			factor( 
				cit , 
				levels = 1:5 , 
				labels = 
					c( 
						'born in the u.s.' ,
						'born in the territories' ,
						'born abroad to american parents' ,
						'naturalized citizen' ,
						'non-citizen'
					)
			) ,
		
		poverty_level = as.numeric( povpip ) ,
		
		married = as.numeric( mar %in% 1 ) ,
		
		sex = factor( sex , labels = c( 'male' , 'female' ) )
	)
~~~


group_by_variable: cit
linear_variable: poverty_level
linear_narm: , na.rm = TRUE
categorical_variable: sex
ratio_estimation_numerator: ssip
ratio_estimation_denominator: pincp
ratio_narm: , na.rm = TRUE
subset_definition: agep >= 65
subset_definition_description: senior citizens
binary_variable: married





needs_srvyr_block: yes



~~~{convey_block}
---

## Poverty and Inequality Estimation with `convey` \\ {-}

The R `convey` library estimates measures of income concentration, poverty, inequality, and wellbeing.  [This textbook](https://guilhermejacob.github.io/context/) details the available features.  As a starting point for CHAPTER_TAG users, this code calculates the gini coefficient on complex sample survey data:

```{r eval = FALSE , results = "hide" }
library(convey)
chapter_tag_design <- convey_prep( chapter_tag_design )

svygini( ~ hincp , chapter_tag_design , na.rm = TRUE )
```
~~~



~~~{replication_example_block}
## Replication Example {-}

The example below matches statistics, standard errors, and margin of errors from the [2021 PUMS tallies](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/estimates/pums_estimates_21.csv):

Match the sum of the weights:

```{r eval = FALSE , results = "hide" }
stopifnot( round( coef( svytotal( ~ one , chapter_tag_design ) ) , 0 ) == 5039877 )
```
	
	
Compute the population by age:

```{r eval = FALSE , results = "hide" }
pums_estimate <- 
	c(288139L, 299245L, 336727L, 334606L, 327102L, 635004L, 641405L, 
	615709L, 335431L, 341926L, 538367L, 265742L, 80474L)

pums_standard_error <- 
	c(2727L, 5368L, 6067L, 4082L, 4485L, 5716L, 4420L, 3706L, 4836L, 
	5100L, 2158L, 3363L, 3186L)

pums_margin_of_error <- 
	c(4486L, 8830L, 9981L, 6715L, 7378L, 9402L, 7271L, 6096L, 7956L, 
	8389L, 3550L, 5532L, 5240L)

results <-
	svytotal( 
		~ as.numeric( agep %in% 0:4 ) +
		as.numeric( agep %in% 5:9 ) +
		as.numeric( agep %in% 10:14 ) +
		as.numeric( agep %in% 15:19 ) +
		as.numeric( agep %in% 20:24 ) +
		as.numeric( agep %in% 25:34 ) +
		as.numeric( agep %in% 35:44 ) +
		as.numeric( agep %in% 45:54 ) +
		as.numeric( agep %in% 55:59 ) +
		as.numeric( agep %in% 60:64 ) +
		as.numeric( agep %in% 65:74 ) +
		as.numeric( agep %in% 75:84 ) +
		as.numeric( agep %in% 85:100 ) , 
		chapter_tag_design
	)

stopifnot( all( round( coef( results ) , 0 ) == pums_estimate ) )

stopifnot( all( round( SE( results ) , 0 ) == pums_standard_error ) )

stopifnot( all( round( SE( results ) * 1.645 , 0 ) == pums_margin_of_error ) )

```

~~~











