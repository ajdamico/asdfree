chapter_title: American Community Survey

~~~{dataset_introduction}
The US Census Bureau's annual replacement for the long-form decennial census.
~~~

table_structure: * One table with one row per household and a second table with one row per individual within each household.

generalizable_population: * The civilian population of the United States.

publication_period: * Released annually since 2005.

administrative_organization: * Administered and financed by the [US Census Bureau](http://www.census.gov/).


catalog_subset_description: # 2016 alabama single-year only. remove ` & stateab == 'al'` for a nationwide table
catalog_subset: chapter_tag_cat <- subset( chapter_tag_cat , year == 2016 & time_period == '1-Year' & stateab == 'al' )


~~~{analysis_examples_survey_design}
library(survey)

# because of the catalog subset above
# the `merged.rds` file is alabama only
chapter_tag_design <-
	svrepdesign(
		weight = ~pwgtp ,
		repweights = 'pwgtp[0-9]+' ,
		scale = 4 / 80 ,
		rscales = rep( 1 , 80 ) ,
		mse = TRUE ,
		type = 'JK1' ,
		data = chapter_tag_df
	)
~~~


~~~{variable_recoding_block}
chapter_tag_design <-
	update(
		
		chapter_tag_design ,
		
		relp = as.numeric( relp ) ,
		
		state_name =
			factor(
				as.numeric( st ) ,
				levels = 
					c(1L, 2L, 4L, 5L, 6L, 8L, 9L, 10L, 
					11L, 12L, 13L, 15L, 16L, 17L, 18L, 
					19L, 20L, 21L, 22L, 23L, 24L, 25L, 
					26L, 27L, 28L, 29L, 30L, 31L, 32L, 
					33L, 34L, 35L, 36L, 37L, 38L, 39L, 
					40L, 41L, 42L, 44L, 45L, 46L, 47L, 
					48L, 49L, 50L, 51L, 53L, 54L, 55L, 
					56L, 72L) ,
				labels =
					c("Alabama", "Alaska", "Arizona", "Arkansas", "California", 
					"Colorado", "Connecticut", "Delaware", "District of Columbia", 
					"Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", 
					"Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", 
					"Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", 
					"Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", 
					"New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", 
					"Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", 
					"South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", 
					"Washington", "West Virginia", "Wisconsin", "Wyoming", "Puerto Rico")
			) ,
		
		cit =
			factor( 
				cit , 
				levels = 1:5 , 
				labels = 
					c( 
						'born in the u.s.' ,
						'born in the territories' ,
						'born abroad to american parents' ,
						'naturalized citizen' ,
						'non-citizen'
					)
			) ,
		
		poverty_level = as.numeric( povpip ) ,
		
		married = as.numeric( mar %in% 1 ) ,
		
		sex = factor( sex , labels = c( 'male' , 'female' ) )
	)
~~~


group_by_variable: cit
linear_variable: poverty_level
linear_narm: , na.rm = TRUE
categorical_variable: sex
ratio_estimation_numerator: ssip
ratio_estimation_denominator: pincp
ratio_narm: , na.rm = TRUE
subset_definition: agep >= 65
subset_definition_description: senior citizens
binary_variable: married

needs_7za_install: yes


~~~{convey_block}
## Poverty and Inequality Estimation with `convey` \\ {-}

The R `convey` library estimates measures of income concentration, poverty, inequality, and wellbeing.  [This textbook](https://guilhermejacob.github.io/context/) details the available features.  As a starting point for CHAPTER_TAG users, this code calculates the gini coefficient on complex sample survey data:

```{r eval = FALSE , results = "hide" }
library(convey)
chapter_tag_design <- convey_prep( chapter_tag_design )

svygini( ~ hincp , chapter_tag_design , na.rm = TRUE )
```
~~~



~~~{replication_example_block}
---

## Replication Example {-}

The example below matches statistics, standard errors, and margin of errors from this table pulled from the [tallies of 2016 PUMS](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/estimates/pums_estimates_16.lst):

`r knitr::include_graphics("images/pums_estimates_16.png")`

Match the sum of the weights:

```{r eval = FALSE , results = "hide" }
stopifnot( round( coef( svytotal( ~ one , chapter_tag_design ) ) , 0 ) == 4863300 )
```
	
	
Compute the population by age:

```{r eval = FALSE , results = "hide" }
pums_estimate <- 
	c( 285681 , 314701 , 300814 , 334318 , 327896 , 629329 , 599719 , 644212 , 
	342205 , 300254 , 464893 , 231293 , 87985 )

pums_standard_error <- 
	c( 2888 , 5168 , 5009 , 3673 , 3521 , 4825 , 4088 , 
	4398 , 5329 , 5389 , 1938 , 3214 , 2950 )

pums_margin_of_error <- 
	c( 4751 , 8501 , 8240 , 6043 , 5792 , 7937 , 6725 , 
	7234 , 8767 , 8865 , 3188 , 5287 , 4853 )

results <-
	svytotal( 
		~ as.numeric( agep %in% 0:4 ) +
		as.numeric( agep %in% 5:9 ) +
		as.numeric( agep %in% 10:14 ) +
		as.numeric( agep %in% 15:19 ) +
		as.numeric( agep %in% 20:24 ) +
		as.numeric( agep %in% 25:34 ) +
		as.numeric( agep %in% 35:44 ) +
		as.numeric( agep %in% 45:54 ) +
		as.numeric( agep %in% 55:59 ) +
		as.numeric( agep %in% 60:64 ) +
		as.numeric( agep %in% 65:74 ) +
		as.numeric( agep %in% 75:84 ) +
		as.numeric( agep %in% 85:100 ) , 
		chapter_tag_design
	)

stopifnot( all( round( coef( results ) , 0 ) == pums_estimate ) )

stopifnot( all( round( SE( results ) , 0 ) == pums_standard_error ) )

stopifnot( all( round( SE( results ) * 1.645 , 0 ) == pums_margin_of_error ) )

```

~~~











needs_actions_build_status_line: yes

~~~{download_and_import_block}

load the haven library to import sas files
```{r eval = FALSE }
# install.packages( 'haven' )
library(haven)
```


download and import the alabama household file
(switch `unix_hal` to `unix_hus` for the entire country)
```{r eval = FALSE }
tf_household <- tempfile()

this_url_household <-
	"https://www2.census.gov/programs-surveys/acs/data/pums/2016/1-Year/unix_hal.zip"

download.file( this_url_household , tf_household , mode = 'wb' )

unzipped_files_household <- unzip( tf_household , exdir = tempdir() )

chapter_tag_sas_household <-
	grep( '\\\\.sas7bdat$' , unzipped_files_household , value = TRUE )

chapter_tag_df_household <- haven::read_sas( chapter_tag_sas_household )

names( chapter_tag_df_household ) <- tolower( names( chapter_tag_df_household ) )
```

download and import the alabama person file
(switch `unix_pal` to `unix_pus` for the entire country)
```{r eval = FALSE }
tf_person <- tempfile()

this_url_person <-
	"https://www2.census.gov/programs-surveys/acs/data/pums/2016/1-Year/unix_pal.zip"

download.file( this_url_person , tf_person , mode = 'wb' )

unzipped_files_person <- unzip( tf_person , exdir = tempdir() )

chapter_tag_sas_person <-
	grep( '\\\\.sas7bdat$' , unzipped_files_person , value = TRUE )

chapter_tag_df_person <- haven::read_sas( chapter_tag_sas_person )

names( chapter_tag_df_person ) <- tolower( names( chapter_tag_df_person ) )
```


remove overlapping columns and merge
```{r eval = FALSE }

chapter_tag_df_household[ , 'rt' ] <- NULL

chapter_tag_df_person[ , 'rt' ] <- NULL

chapter_tag_df <-
	merge( chapter_tag_df_household , chapter_tag_df_person )
	
chapter_tag_df[ , 'one' ] <- 1
```
~~~

