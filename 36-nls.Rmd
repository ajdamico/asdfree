# National Longitudinal Surveys (NLS) {-}

needs_travis_build_status_line

The National Longitudinal Surveys follow the same sample of individuals from specific birth cohorts over time. The surveys collect data on labor market activity, schooling, fertility, program participation, and health.

* Multiple panels, each with one table with one row per sampled panel respondent.

* A series of complex sample surveys designed to generalize to various cohorts of Americans born during [designated time periods](https://www.bls.gov/nls/overview.htm).

* Updated biennally for most active panels.

* Administered by the [Bureau of Labor Statistics](http://www.bls.gov/).

## Simplified Download and Importation {-}

The R `lodown` package easily downloads and imports all available NLS microdata by simply specifying `"nls"` with an `output_dir =` parameter in the `lodown()` function. Depending on your internet connection and computer processing speed, you might prefer to run this step overnight.

```{r eval = FALSE }
library(lodown)
lodown( "nls" , output_dir = file.path( path.expand( "~" ) , "NLS" ) )
```

`lodown` also provides a catalog of available microdata extracts with the `get_catalog()` function. After requesting the NLS catalog, you could pass a subsetted catalog through the `lodown()` function in order to download and import specific extracts (rather than all available extracts).

```{r eval = FALSE , results = "hide" }
library(lodown)
# examine all available NLS microdata files
nls_cat <-
	get_catalog( "nls" ,
		output_dir = file.path( path.expand( "~" ) , "NLS" ) )

# National Longitudinal Survey of Youth, 1997 only
nls_cat <- subset( nls_cat , study_name == 'NLS Youth 1997 (NLSY97)' )
# download the microdata to your local computer
nls_cat <- lodown( "nls" , nls_cat )
```

## Analysis Examples with the `survey` library \ {-}

Construct a complex sample survey design:

```{r eval = FALSE }

```

```{r eval = FALSE }
options( survey.lonely.psu = "adjust" )

library(survey)

nlsy_files <- 
	list.files(
		file.path( path.expand( "~" ) , "NLS" ) ,
		full.names = TRUE ,
		recursive = TRUE
	)

# read in the R loading script
nlsy97_r <- 
	readLines( nlsy_files[ grepl( "nlsy97(.*)R$" , basename( nlsy_files ) ) ] )

# find all instances of "data$" in the r script
data_dollar <- grep( "data\\$" , nlsy97_r )
	
# extract the column names from the R script
first_line <- grep( "names(new_data) <-" , nlsy97_r , fixed = TRUE )
close_parentheses <- grep( ")" , nlsy97_r , fixed = TRUE )
last_line <- min( close_parentheses[ close_parentheses > first_line ] )
column_names_lines <- nlsy97_r[ seq( first_line , last_line ) ]
column_names_lines <- 
	gsub( 'names(new_data) <-' , 'column_names <-' , column_names_lines , fixed = TRUE )
eval( parse( text = column_names_lines ) )

# choose which columns to import
columns_to_import <-
	c( 'R0000100' , 'T5206900' , 'R9829600' , 'R0536300' , 
	'Z9061800' , 'T6657200' , 'R1205300' , 'T7545600' )

	
# for each column to import, look for a recoding block
find_recoding_block <-
	function( w ){
		
		this_block_start <- min( grep( paste0( "data\\$" , w ) , nlsy97_r ) )
		
		recode_lines <- 
			seq( 
				this_block_start , 
				min( data_dollar[ data_dollar > this_block_start ] ) - 1 
			)
			
		paste( nlsy97_r[ recode_lines ] , collapse = '' )
		
	}

recodes_to_run <- unlist( lapply( columns_to_import , find_recoding_block ) )
	
# readr::read_delim() columns must match their order in the csv file
columns_to_import <-
	columns_to_import[ order( match( columns_to_import , column_names ) ) ]

	
# confirm all column names are available
stopifnot( all( columns_to_import %in% column_names ) )

# identify the .dat file
nlsy97_dat <- nlsy_files[ grepl( "nlsy97(.*)dat$" , basename( nlsy_files ) ) ]

nls_variables_df <- 
	data.frame( 
		readr::read_delim( 
			nlsy97_dat , 
			col_names = columns_to_import , 
			col_types = 
				paste0( 
					ifelse( column_names %in% columns_to_import , 'n' , '_' ) , 
					collapse = "" 
				) ,
			delim = ' '
		) 
	)

# remove all missings
nls_variables_df[ nls_variables_df < 0 ] <- NA

recodes_to_run <- 
	gsub( "data\\$" , "nls_variables_df$" , recodes_to_run )

# align the main variables with what the R script says	
for( this_recode in recodes_to_run ) eval( parse( text = this_recode ) )

# cluster and strata variables
nls_psustr_df <-
	readRDS( grep( "strpsu\\.rds$" , nlsy_files , value = TRUE ) )
	
# you can read more about longitudinal weights here
# http://www.nlsinfo.org/weights

# the get_nlsy_weights function returns a data.frame object
# containing the unique person identifiers and also a column of weights.

# view which points-in-time are available for a particular study
# get_nlsy_selections( "nlsy97" )

# download weights for respondents in 1997
w <- nls_get_weights( "nlsy97" , 'YES' , 'SURV1997' )

# download weights for respondents who were in any of the 1997, 2002, or 2007 surveys
# w <- 
# 	nls_get_weights( "nlsy97" , 'YES' , c( 'SURV1997' , 'SURV2002' , 'SURV2007' ) )

# download weights for respondents who were in all of the 1997, 2002, and 2007 surveys
# w <- 
# 	nls_get_weights( "nlsy97" , 'NO' , c( 'SURV1997' , 'SURV2002' , 'SURV2007' ) )

# download weights for respondents who are in all available surveys
# w <- 
# 	nls_get_weights( "nlsy97" , "NO" , nls_get_selections( "nlsy97" ) )

# merge weights with cluster and strata variables
nls_survey_df <- merge( nls_psustr_df , w )

# merge variables onto survey design
nls_df <- merge( nls_variables_df , nls_survey_df )

nls_design <- 
	svydesign( 
		~ R1489800 , 
		strata = ~ R1489700 , 
		data = nls_df ,
		weights = ~ weight ,
		nest = TRUE
	)
```

### Variable Recoding {-}

Add new columns to the data set:
```{r eval = FALSE }
nls_design <- 
	update( 
		nls_design , 
		one = 1 ,
		bachelors_degree_or_higher = 
			as.numeric( as.numeric( T6657200 ) >= 5 )
	)
```

### Unweighted Counts {-}

Count the unweighted number of records in the survey sample, overall and by groups:
```{r eval = FALSE , results = "hide" }
sum( weights( nls_design , "sampling" ) != 0 )

svyby( ~ one , ~ R1205300 , nls_design , unwtd.count )
```

### Weighted Counts {-}
Count the weighted size of the generalizable population, overall and by groups:
```{r eval = FALSE , results = "hide" }
svytotal( ~ one , nls_design )

svyby( ~ one , ~ R1205300 , nls_design , svytotal )
```

### Descriptive Statistics {-}

Calculate the mean (average) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svymean( ~ T7545600 , nls_design , na.rm = TRUE )

svyby( ~ T7545600 , ~ R1205300 , nls_design , svymean , na.rm = TRUE )
```

Calculate the distribution of a categorical variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svymean( ~ T6657200 , nls_design , na.rm = TRUE )

svyby( ~ T6657200 , ~ R1205300 , nls_design , svymean , na.rm = TRUE )
```

Calculate the sum of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svytotal( ~ T7545600 , nls_design , na.rm = TRUE )

svyby( ~ T7545600 , ~ R1205300 , nls_design , svytotal , na.rm = TRUE )
```

Calculate the weighted sum of a categorical variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svytotal( ~ T6657200 , nls_design , na.rm = TRUE )

svyby( ~ T6657200 , ~ R1205300 , nls_design , svytotal , na.rm = TRUE )
```

Calculate the median (50th percentile) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
svyquantile( ~ T7545600 , nls_design , 0.5 , na.rm = TRUE )

svyby( 
	~ T7545600 , 
	~ R1205300 , 
	nls_design , 
	svyquantile , 
	0.5 ,
	ci = TRUE ,
	keep.var = TRUE ,
	na.rm = TRUE
)
```

Estimate a ratio:
```{r eval = FALSE , results = "hide" }
svyratio( 
	numerator = ~ R9829600 , 
	denominator = ~ T7545600 , 
	nls_design ,
	na.rm = TRUE
)
```

### Subsetting {-}

Restrict the survey design to raised by only biological mother or father in 1997:
```{r eval = FALSE , results = "hide" }
sub_nls_design <- subset( nls_design , as.numeric( R1205300 ) %in% 4:5 )
```
Calculate the mean (average) of this subset:
```{r eval = FALSE , results = "hide" }
svymean( ~ T7545600 , sub_nls_design , na.rm = TRUE )
```

### Measures of Uncertainty {-}

Extract the coefficient, standard error, confidence interval, and coefficient of variation from any descriptive statistics function result, overall and by groups:
```{r eval = FALSE , results = "hide" }
this_result <- svymean( ~ T7545600 , nls_design , na.rm = TRUE )

coef( this_result )
SE( this_result )
confint( this_result )
cv( this_result )

grouped_result <-
	svyby( 
		~ T7545600 , 
		~ R1205300 , 
		nls_design , 
		svymean ,
		na.rm = TRUE 
	)
	
coef( grouped_result )
SE( grouped_result )
confint( grouped_result )
cv( grouped_result )
```

Calculate the degrees of freedom of any survey design object:
```{r eval = FALSE , results = "hide" }
degf( nls_design )
```

Calculate the complex sample survey-adjusted variance of any statistic:
```{r eval = FALSE , results = "hide" }
svyvar( ~ T7545600 , nls_design , na.rm = TRUE )
```

Include the complex sample design effect in the result for a specific statistic:
```{r eval = FALSE , results = "hide" }
# SRS without replacement
svymean( ~ T7545600 , nls_design , na.rm = TRUE , deff = TRUE )

# SRS with replacement
svymean( ~ T7545600 , nls_design , na.rm = TRUE , deff = "replace" )
```

Compute confidence intervals for proportions using methods that may be more accurate near 0 and 1. See `?svyciprop` for alternatives:
```{r eval = FALSE , results = "hide" }
svyciprop( ~ bachelors_degree_or_higher , nls_design ,
	method = "likelihood" , na.rm = TRUE )
```

### Regression Models and Tests of Association {-}

Perform a design-based t-test:
```{r eval = FALSE , results = "hide" }
svyttest( T7545600 ~ bachelors_degree_or_higher , nls_design )
```

Perform a chi-squared test of association for survey data:
```{r eval = FALSE , results = "hide" }
svychisq( 
	~ bachelors_degree_or_higher + T6657200 , 
	nls_design 
)
```

Perform a survey-weighted generalized linear model:
```{r eval = FALSE , results = "hide" }
glm_result <- 
	svyglm( 
		T7545600 ~ bachelors_degree_or_higher + T6657200 , 
		nls_design 
	)

summary( glm_result )
```

## Analysis Examples with `srvyr` \ {-}

The R `srvyr` library calculates summary statistics from survey data, such as the mean, total or quantile using [dplyr](https://github.com/tidyverse/dplyr/)-like syntax. [srvyr](https://github.com/gergness/srvyr) allows for the use of many verbs, such as `summarize`, `group_by`, and `mutate`, the convenience of pipe-able functions, the `tidyverse` style of non-standard evaluation and more consistent return types than the `survey` package. [This vignette](https://cran.r-project.org/web/packages/srvyr/vignettes/srvyr-vs-survey.html) details the available features. As a starting point for NLS users, this code replicates previously-presented examples:

```{r eval = FALSE , results = "hide" }
library(srvyr)
nls_srvyr_design <- as_survey( nls_design )
```
Calculate the mean (average) of a linear variable, overall and by groups:
```{r eval = FALSE , results = "hide" }
nls_srvyr_design %>%
	summarize( mean = survey_mean( T7545600 , na.rm = TRUE ) )

nls_srvyr_design %>%
	group_by( R1205300 ) %>%
	summarize( mean = survey_mean( T7545600 , na.rm = TRUE ) )
```


